{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05bcb7e2",
   "metadata": {},
   "source": [
    "# Experiment 13: Model building using full dataset (Surface Elevation, U- and V-velocity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5106d18a",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57eec38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d668df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages:\n",
    "import mikeio\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "plt.style.use(\"seaborn-v0_8-whitegrid\")\n",
    "\n",
    "from Scripts import my_functions as mf\n",
    "from Scripts import my_models3 as mm\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA, IncrementalPCA\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "\n",
    "from IPython.display import HTML\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33dd91ef",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46063981",
   "metadata": {},
   "source": [
    "### Combine data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "323fa0fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dfsu2D\n",
       "number of elements: 17980\n",
       "number of nodes: 10460\n",
       "projection: LONG/LAT\n",
       "items:\n",
       "  0:  Surface elevation <Surface Elevation> (meter)\n",
       "  1:  Total water depth <Water Depth> (meter)\n",
       "  2:  U velocity <u velocity component> (meter per sec)\n",
       "  3:  V velocity <v velocity component> (meter per sec)\n",
       "time: 18191 steps with dt=1800.0s\n",
       "      1996-12-18 00:00:00 -- 1997-12-31 23:00:00"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Find the relative path to Data/DHI_wk_sim/Area.dfsu from current directory:\n",
    "\n",
    "# Go up two levels from current directory:\n",
    "path = os.path.abspath(os.path.join(os.getcwd(), os.pardir, os.pardir))\n",
    "\n",
    "# Define path to dfsu file:\n",
    "path_area = os.path.join(path, \"Data/DHI_yr_sim/Area.dfsu\")\n",
    "\n",
    "path_wind = os.path.join(path, \"Data/DHI_yr_sim/HD_OERESUND_CREA6_1997_v2.m21fm - Result Files/wind.dfs0\")\n",
    "\n",
    "# Define paths to boundary conditions:\n",
    "path_bc_north = os.path.join(path, \"Data/DUMP/waterlevel_bc/waterlevel_north.dfs1\")\n",
    "path_bc_south = os.path.join(path, \"Data/DUMP/waterlevel_bc/waterlevel_south.dfs1\")\n",
    "\n",
    "# Open dfsu file:\n",
    "mikeio.open(path_area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f52d7253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute = 0\n",
      "Wall time: 9.33 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Auxilliary variable:\n",
    "compute = 1\n",
    "\n",
    "# Try to load results from earlier runs:\n",
    "if 1:\n",
    "    \n",
    "    # Load combined data if available:\n",
    "    if os.path.exists(\"../../Data/my_data/data.pkl\"):\n",
    "        \n",
    "        # Load dataframe:\n",
    "        with open(\"../../Data/my_data/data.pkl\", \"rb\") as f:\n",
    "            df_full = pkl.load(f)\n",
    "            \n",
    "        # Change compute to 0:\n",
    "        compute = 0\n",
    "        \n",
    "print(f\"compute = {compute}\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d31df837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Compute the combined data if not available: (~ 10 min)\n",
    "if compute:\n",
    "    \n",
    "    # Extract time:\n",
    "    time_data = mikeio.open(path_area).time\n",
    "\n",
    "    # Load files:\n",
    "    zuv_data  = mikeio.read(path_area,\n",
    "                           time=time_data)\n",
    "    wind_data = mikeio.read(path_wind,\n",
    "                           time=time_data)\n",
    "\n",
    "    bc_north_data = mikeio.read(path_bc_north,\n",
    "                               time=time_data)\n",
    "    bc_south_data = mikeio.read(path_bc_south,\n",
    "                               time=time_data)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Extract values of surface elevation, u-velocity and v-velocity from zuv_data:\n",
    "    z_vals = zuv_data[\"Surface elevation\"].values\n",
    "    u_vals = zuv_data[\"U velocity\"].values\n",
    "    v_vals = zuv_data[\"V velocity\"].values\n",
    "\n",
    "    # Extract values of u-velocity and v-velocity from wind_data:\n",
    "    wu_vals = np.concatenate([wind_data[i].values.reshape(-1,1) for i in range(25)], axis=1)\n",
    "    wv_vals = np.concatenate([wind_data[i].values.reshape(-1,1) for i in range(25, 50)], axis=1)\n",
    "\n",
    "    # Extract values of bc_north_data and bc_south_data:\n",
    "    bcn_vals = bc_north_data[\"North\"].values\n",
    "    bcs_vals = bc_south_data[\"South\"].values\n",
    "\n",
    "    \n",
    "    # Create dataframes:\n",
    "    df_z = pd.DataFrame(z_vals).add_prefix(\"z_\")\n",
    "    df_u = pd.DataFrame(u_vals).add_prefix(\"u_\")\n",
    "    df_v = pd.DataFrame(v_vals).add_prefix(\"v_\")\n",
    "    \n",
    "    df_wu = pd.DataFrame(wu_vals).add_prefix(\"wu_\")\n",
    "    df_wv = pd.DataFrame(wv_vals).add_prefix(\"wv_\")\n",
    "\n",
    "    df_bcn = pd.DataFrame(bcn_vals).add_prefix(\"bcn_\")\n",
    "    df_bcs = pd.DataFrame(bcs_vals).add_prefix(\"bcs_\")\n",
    "    \n",
    "    \n",
    "    # Combine everything:\n",
    "    df_full = pd.concat([df_z, df_u, df_v, \n",
    "                         df_bcn, df_bcs, \n",
    "                         df_wu, df_wv], axis=1)\n",
    "    \n",
    "    # Set datetime as index:\n",
    "    df_full.set_index(time_data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c9b71d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Save combined data:\n",
    "if compute:\n",
    "    \n",
    "    with open(\"../../Data/my_data/data.pkl\", \"wb\") as f:\n",
    "        pkl.dump(df, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64eb759",
   "metadata": {},
   "source": [
    "### Create or load PCA and scaler:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59467bb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute = 0\n"
     ]
    }
   ],
   "source": [
    "# Auxilliary variable:\n",
    "compute = 1\n",
    "\n",
    "# Try to load results from earlier runs:\n",
    "if 1:\n",
    "    \n",
    "    # Load scaler and pca if they exist:\n",
    "    if os.path.exists(\"../Data_Results/Exp_13_scaler.pkl\") and \\\n",
    "       os.path.exists(\"../Data_Results/Exp_13_pca.pkl\"):\n",
    "        \n",
    "        # Load scaler:\n",
    "        with open(\"../Data_Results/Exp_13_scaler.pkl\", \"rb\") as f:\n",
    "            scaler = pkl.load(f)\n",
    "            \n",
    "        # Load pca:\n",
    "        with open(\"../Data_Results/Exp_13_pca.pkl\", \"rb\") as f:\n",
    "            ipca = pkl.load(f)\n",
    "        \n",
    "        \n",
    "        # Change compute to 0:\n",
    "        compute = 0\n",
    "        \n",
    "print(f\"compute = {compute}\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6691588a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1dec65d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 791 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Create small dataframe:\n",
    "df = df_full.iloc[:3200].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b70d329",
   "metadata": {},
   "source": [
    "## Extract data:\n",
    "\n",
    "#### Split data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a38fec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600, 54004) (1600, 54004)\n",
      "Wall time: 2.45 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "# Train test split:\n",
    "tts = int(0.5 * len(df) // 1)\n",
    "\n",
    "df_train = df.iloc[:tts]\n",
    "df_test = df.iloc[tts:]\n",
    "\n",
    "print(df_train.shape, df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e17061",
   "metadata": {},
   "source": [
    "#### Feature extractor method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87b30cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(df):\n",
    "    \n",
    "    # Surface elevation, U- and V-velocity:\n",
    "    z_data = df.filter(regex=\"z_\").values\n",
    "    u_data = df.filter(regex=\"^u_\").values\n",
    "    v_data = df.filter(regex=\"^v_\").values\n",
    "    \n",
    "    # North and south BC data:\n",
    "    bcn_data = df.filter(regex=\"bcn_\").values\n",
    "    bcs_data = df.filter(regex=\"bcs_\").values\n",
    "    \n",
    "    # U- and V- wind velocity data:\n",
    "    wu_data = df.filter(regex=\"wu_\").values\n",
    "    wv_data = df.filter(regex=\"wv_\").values\n",
    "    \n",
    "    data_list = {\"z\"  :   z_data, \"u\"  :   u_data, \"v\" : v_data,\n",
    "                 \"bcn\": bcn_data, \"bcs\": bcs_data,\n",
    "                 \"wu\" :  wu_data, \"wv\" :  wv_data}\n",
    "    \n",
    "    return data_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900b4bdc",
   "metadata": {},
   "source": [
    "**Prediction model comparison method:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d36eb8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_models(models):\n",
    "    \n",
    "    xs = range(len(df_train)+len(df_test))\n",
    "    x_train = xs[:len(df_train)]\n",
    "    x_test = xs[len(df_train):]\n",
    "    \n",
    "    plt.figure(figsize=(12,8), dpi=100)\n",
    "    plt.title(f\"Model comparison\", \n",
    "              fontsize=16)\n",
    "    \n",
    "    plot_colors = []\n",
    "    \n",
    "    min_err = 10\n",
    "    \n",
    "    # Plot training errors:\n",
    "    for model in models:\n",
    "    \n",
    "        train_errors = model.model[\"train_errors\"]\n",
    "        train_line,  = plt.plot(x_train, train_errors)\n",
    "        \n",
    "        plot_colors.append(train_line.get_color())\n",
    "        \n",
    "        if train_errors.min() < min_err: \n",
    "            min_err = train_errors.min()\n",
    "        \n",
    "    # Setup yscale and vertical line:\n",
    "    my_yticks = [1]+[1/(10**i) for i in range(1,10)]\n",
    "    \n",
    "    good_yticks = np.argwhere(np.array(my_yticks) < min_err)\n",
    "    \n",
    "    if len(good_yticks) > 2:\n",
    "        my_yticks = my_yticks[:good_yticks[2][0]]\n",
    "    \n",
    "    plt.vlines(x=len(x_train), ymin=my_yticks[-1], ymax=my_yticks[0], color=\"black\",\n",
    "           linestyle=\"dashed\")\n",
    "    \n",
    "    # Plot test errors:\n",
    "    for i, model in enumerate(models):\n",
    "        \n",
    "        test_errors = model.model[\"test_errors\"]\n",
    "        test_line,  = plt.plot(x_test, test_errors,\n",
    "                               color=plot_colors[i],\n",
    "                               linestyle=\"dotted\")\n",
    "        \n",
    "        if test_errors.min() < min_err:\n",
    "            min_err = test_errors.min()\n",
    "        \n",
    "        \n",
    "    plt.xlabel(\"Time steps\", fontsize=14)\n",
    "    plt.ylabel(\"RMSE\", fontsize=14)\n",
    "    \n",
    "    plt.legend([model.name for model in models]+[\"Train-Test-Split\"],\n",
    "                fontsize=11, frameon=True, fancybox=True,\n",
    "                shadow=True, framealpha=1, facecolor=\"lightgrey\")\n",
    "    \n",
    "    \n",
    "    plt.yscale(\"log\")\n",
    "    \n",
    "    plt.yticks(my_yticks)\n",
    "    \n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35d2fa1",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea9f3bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check other my_models.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c35338",
   "metadata": {},
   "source": [
    "## Model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3889eee1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if 0:\n",
    "    m = mm.my_models.PCA_Multistep_Regression_Z_BC(pca_bs=256, pca_comps=10, ar=1)\n",
    "    m.run(df_train, df_test)\n",
    "    m.plot_errors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "460ee0f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init was run.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "M = mm.MyModels(df, \"standard\", \"pca\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4edc4a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "M1 = M.BaselineModel([\"z\"], \"Baseline\", train_frac=0.25)\n",
    "M2 = M.BaselineModel([\"z\"], \"Coordinate\", train_frac=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "56ad281e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_frac = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "be7294bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup models:\n",
    "models = [\n",
    "    M.BaselineModel([\"z\"], \"Collective\", train_frac=train_frac),\n",
    "    M.BaselineModel([\"z\"], \"Coordinate\", train_frac=train_frac),\n",
    "    M.RegressionModel(\"linear\", [\"z\"], [\"z\"], latent_dim=1, state_lag=1, boundary=True, wind=False, extra_lag=2, train_frac=train_frac)\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c9b6699b",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (Temp/ipykernel_2428/1100403116.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\EMILSI~1\\AppData\\Local\\Temp/ipykernel_2428/1100403116.py\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    M.\u001b[0m\n\u001b[1;37m      ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "48bf1a54",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'BaselineModel' object has no attribute 'name'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\EMILSI~1\\AppData\\Local\\Temp/ipykernel_2428/909218461.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Desktop\\Master_Thesis\\Coding\\Notebooks\\..\\Scripts\\my_models3.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    350\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmeans\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 352\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34mf\", n_train: {self.n_train}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    353\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'BaselineModel' object has no attribute 'name'"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1504db1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    print(mf.rmse(model.output_data[\"z\"], model.output_preds[\"z\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a61558c",
   "metadata": {},
   "outputs": [],
   "source": [
    "models[0].output_preds[\"z\"].iloc[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6b025d",
   "metadata": {},
   "outputs": [],
   "source": [
    "models[1].output_preds[\"z\"].iloc[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aeeab8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(models[0].output_preds[\"z\"])):\n",
    "    if i % 100 == 0:\n",
    "#        print((models[0].means[\"z\"]).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec499048",
   "metadata": {},
   "outputs": [],
   "source": [
    "models[0].output_preds[\"z\"].iloc[0, :] = models[0].means[\"z\"]\n",
    "models[0].output_preds[\"z\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f0753b",
   "metadata": {},
   "outputs": [],
   "source": [
    "M1.output_data[\"z\"].mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435dbb48",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mf.rmse(M1.output_data[\"z\"], M1.output_preds[\"z\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145e46e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "M1.n_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc1e45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "M1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03b87f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        \n",
    "          \n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe072c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in tqdm(models):\n",
    "    model.fit().predict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d7cc20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b17a371",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [mm.my_models().Baseline(),\n",
    "          mm.my_models().Coordinate_Baseline(),\n",
    "          mm.my_models().PCAReconstruction(),\n",
    "          \n",
    "          mm.my_models().PCA_Multistep_Regression_Z(pca_bs = 100, pca_comps=10, ar=1),\n",
    "          mm.my_models().PCA_Multistep_Regression_BC(pca_bs = 100, pca_comps=10, ar=1),\n",
    "          mm.my_models().PCA_Multistep_Regression_Z_BC(pca_bs = 100, pca_comps=10, ar=1),\n",
    "          mm.my_models().PCA_Regression_Z_BC(pca_bs=100, pca_comps=10),\n",
    "          \n",
    "          mm.my_models().PCA_Multistep_Regression_Z(pca_bs = 100, pca_comps=10, ar=2),\n",
    "          mm.my_models().PCA_Multistep_Regression_BC(pca_bs = 100, pca_comps=10, ar=2),\n",
    "          mm.my_models().PCA_Multistep_Regression_Z_BC(pca_bs = 100, pca_comps=10, ar=2),\n",
    "          \n",
    "          mm.my_models().PCA_Multistep_Regression_Z(pca_bs=100, pca_comps=10, ar=3),\n",
    "          mm.my_models().PCA_Multistep_Regression_BC(pca_bs=100, pca_comps=10, ar=3),\n",
    "          mm.my_models().PCA_Multistep_Regression_Z_BC(pca_bs=100, pca_comps=10, ar=3),]\n",
    "          \n",
    "\n",
    "\n",
    "for model in models:\n",
    "    print(f\"Running model: {model.name}\")\n",
    "    model.run(df_train, df_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692f29af",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    model.plot_errors()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6975ba",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"Names\": [i.name for i in models],\n",
    "                   \"Avg. Train. Err.\": [i.model[\"train_errors\"].mean() for i in models],\n",
    "                   \"Avg. Train. Rank.\": np.argsort(np.argsort(np.array([i.model[\"train_errors\"].mean() for i in models]))),\n",
    "                   \"Avg. Test. Err.\": [i.model[\"test_errors\"].mean() for i in models],\n",
    "                   \"Avg. Test. Rank.\": np.argsort(np.argsort(np.array([i.model[\"test_errors\"].mean() for i in models])))})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6c8031",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "compare_models(models[-3:]+[models[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1507ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "compare_models(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208f1953",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca47b99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = mm.my_models().PCA_Multistep_Regression_BC(pca_bs=100, pca_comps=1, ar=3)\n",
    "m.run(df_train, df_test)\n",
    "m.plot_errors()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe421c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "m.model[\"y_train_pred\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a737a904",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = mm.my_models().PCA_Multistep_Regression_BC(pca_bs=100, pca_comps=2, ar=3)\n",
    "m.run(df_train, df_test)\n",
    "m.plot_errors()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
