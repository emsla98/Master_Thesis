{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05bcb7e2",
   "metadata": {},
   "source": [
    "# Experiment 13: Model building using full dataset (Surface Elevation, U- and V-velocity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5106d18a",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57eec38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d668df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages:\n",
    "import mikeio\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "plt.style.use(\"seaborn-v0_8-whitegrid\")\n",
    "\n",
    "from Scripts import my_functions as mf\n",
    "from Scripts import my_models3 as mm\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA, IncrementalPCA\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "\n",
    "from IPython.display import HTML\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33dd91ef",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46063981",
   "metadata": {},
   "source": [
    "### Combine data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "323fa0fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dfsu2D\n",
       "number of elements: 17980\n",
       "number of nodes: 10460\n",
       "projection: LONG/LAT\n",
       "items:\n",
       "  0:  Surface elevation <Surface Elevation> (meter)\n",
       "  1:  Total water depth <Water Depth> (meter)\n",
       "  2:  U velocity <u velocity component> (meter per sec)\n",
       "  3:  V velocity <v velocity component> (meter per sec)\n",
       "time: 18191 steps with dt=1800.0s\n",
       "      1996-12-18 00:00:00 -- 1997-12-31 23:00:00"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Find the relative path to Data/DHI_wk_sim/Area.dfsu from current directory:\n",
    "\n",
    "# Go up two levels from current directory:\n",
    "path = os.path.abspath(os.path.join(os.getcwd(), os.pardir, os.pardir))\n",
    "\n",
    "# Define path to dfsu file:\n",
    "path_area = os.path.join(path, \"Data/DHI_yr_sim/Area.dfsu\")\n",
    "\n",
    "path_wind = os.path.join(path, \"Data/DHI_yr_sim/HD_OERESUND_CREA6_1997_v2.m21fm - Result Files/wind.dfs0\")\n",
    "\n",
    "# Define paths to boundary conditions:\n",
    "path_bc_north = os.path.join(path, \"Data/DUMP/waterlevel_bc/waterlevel_north.dfs1\")\n",
    "path_bc_south = os.path.join(path, \"Data/DUMP/waterlevel_bc/waterlevel_south.dfs1\")\n",
    "\n",
    "# Open dfsu file:\n",
    "mikeio.open(path_area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f52d7253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute = 0\n",
      "Wall time: 9.44 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Auxilliary variable:\n",
    "compute = 1\n",
    "\n",
    "# Try to load results from earlier runs:\n",
    "if 1:\n",
    "    \n",
    "    # Load combined data if available:\n",
    "    if os.path.exists(\"../../Data/my_data/data.pkl\"):\n",
    "        \n",
    "        # Load dataframe:\n",
    "        with open(\"../../Data/my_data/data.pkl\", \"rb\") as f:\n",
    "            df_full = pkl.load(f)\n",
    "            \n",
    "        # Change compute to 0:\n",
    "        compute = 0\n",
    "        \n",
    "print(f\"compute = {compute}\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d31df837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Compute the combined data if not available: (~ 10 min)\n",
    "if compute:\n",
    "    \n",
    "    # Extract time:\n",
    "    time_data = mikeio.open(path_area).time\n",
    "\n",
    "    # Load files:\n",
    "    zuv_data  = mikeio.read(path_area,\n",
    "                           time=time_data)\n",
    "    wind_data = mikeio.read(path_wind,\n",
    "                           time=time_data)\n",
    "\n",
    "    bc_north_data = mikeio.read(path_bc_north,\n",
    "                               time=time_data)\n",
    "    bc_south_data = mikeio.read(path_bc_south,\n",
    "                               time=time_data)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Extract values of surface elevation, u-velocity and v-velocity from zuv_data:\n",
    "    z_vals = zuv_data[\"Surface elevation\"].values\n",
    "    u_vals = zuv_data[\"U velocity\"].values\n",
    "    v_vals = zuv_data[\"V velocity\"].values\n",
    "\n",
    "    # Extract values of u-velocity and v-velocity from wind_data:\n",
    "    wu_vals = np.concatenate([wind_data[i].values.reshape(-1,1) for i in range(25)], axis=1)\n",
    "    wv_vals = np.concatenate([wind_data[i].values.reshape(-1,1) for i in range(25, 50)], axis=1)\n",
    "\n",
    "    # Extract values of bc_north_data and bc_south_data:\n",
    "    bcn_vals = bc_north_data[\"North\"].values\n",
    "    bcs_vals = bc_south_data[\"South\"].values\n",
    "\n",
    "    \n",
    "    # Create dataframes:\n",
    "    df_z = pd.DataFrame(z_vals).add_prefix(\"z_\")\n",
    "    df_u = pd.DataFrame(u_vals).add_prefix(\"u_\")\n",
    "    df_v = pd.DataFrame(v_vals).add_prefix(\"v_\")\n",
    "    \n",
    "    df_wu = pd.DataFrame(wu_vals).add_prefix(\"wu_\")\n",
    "    df_wv = pd.DataFrame(wv_vals).add_prefix(\"wv_\")\n",
    "\n",
    "    df_bcn = pd.DataFrame(bcn_vals).add_prefix(\"bcn_\")\n",
    "    df_bcs = pd.DataFrame(bcs_vals).add_prefix(\"bcs_\")\n",
    "    \n",
    "    \n",
    "    # Combine everything:\n",
    "    df_full = pd.concat([df_z, df_u, df_v, \n",
    "                         df_bcn, df_bcs, \n",
    "                         df_wu, df_wv], axis=1)\n",
    "    \n",
    "    # Set datetime as index:\n",
    "    df_full.set_index(time_data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c9b71d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Save combined data:\n",
    "if compute:\n",
    "    \n",
    "    with open(\"../../Data/my_data/data.pkl\", \"wb\") as f:\n",
    "        pkl.dump(df, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64eb759",
   "metadata": {},
   "source": [
    "### Create or load PCA and scaler:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59467bb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute = 0\n"
     ]
    }
   ],
   "source": [
    "# Auxilliary variable:\n",
    "compute = 1\n",
    "\n",
    "# Try to load results from earlier runs:\n",
    "if 1:\n",
    "    \n",
    "    # Load scaler and pca if they exist:\n",
    "    if os.path.exists(\"../Data_Results/Exp_13_scaler.pkl\") and \\\n",
    "       os.path.exists(\"../Data_Results/Exp_13_pca.pkl\"):\n",
    "        \n",
    "        # Load scaler:\n",
    "        with open(\"../Data_Results/Exp_13_scaler.pkl\", \"rb\") as f:\n",
    "            scaler = pkl.load(f)\n",
    "            \n",
    "        # Load pca:\n",
    "        with open(\"../Data_Results/Exp_13_pca.pkl\", \"rb\") as f:\n",
    "            ipca = pkl.load(f)\n",
    "        \n",
    "        \n",
    "        # Change compute to 0:\n",
    "        compute = 0\n",
    "        \n",
    "print(f\"compute = {compute}\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6691588a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1dec65d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 967 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Create small dataframe:\n",
    "df = df_full.iloc[:3200].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b70d329",
   "metadata": {},
   "source": [
    "## Extract data:\n",
    "\n",
    "#### Split data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a38fec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600, 54004) (1600, 54004)\n",
      "Wall time: 2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "# Train test split:\n",
    "tts = int(0.5 * len(df) // 1)\n",
    "\n",
    "df_train = df.iloc[:tts]\n",
    "df_test = df.iloc[tts:]\n",
    "\n",
    "print(df_train.shape, df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e17061",
   "metadata": {},
   "source": [
    "#### Feature extractor method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87b30cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(df):\n",
    "    \n",
    "    # Surface elevation, U- and V-velocity:\n",
    "    z_data = df.filter(regex=\"z_\").values\n",
    "    u_data = df.filter(regex=\"^u_\").values\n",
    "    v_data = df.filter(regex=\"^v_\").values\n",
    "    \n",
    "    # North and south BC data:\n",
    "    bcn_data = df.filter(regex=\"bcn_\").values\n",
    "    bcs_data = df.filter(regex=\"bcs_\").values\n",
    "    \n",
    "    # U- and V- wind velocity data:\n",
    "    wu_data = df.filter(regex=\"wu_\").values\n",
    "    wv_data = df.filter(regex=\"wv_\").values\n",
    "    \n",
    "    data_list = {\"z\"  :   z_data, \"u\"  :   u_data, \"v\" : v_data,\n",
    "                 \"bcn\": bcn_data, \"bcs\": bcs_data,\n",
    "                 \"wu\" :  wu_data, \"wv\" :  wv_data}\n",
    "    \n",
    "    return data_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114ced14",
   "metadata": {},
   "source": [
    "**Prediction model comparison method:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c03fa61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_models(models):\n",
    "    \n",
    "    xs = range(len(df_train)+len(df_test))\n",
    "    x_train = xs[:len(df_train)]\n",
    "    x_test = xs[len(df_train):]\n",
    "    \n",
    "    plt.figure(figsize=(12,8), dpi=100)\n",
    "    plt.title(f\"Model comparison\", \n",
    "              fontsize=16)\n",
    "    \n",
    "    plot_colors = []\n",
    "    \n",
    "    min_err = 10\n",
    "    \n",
    "    # Plot training errors:\n",
    "    for model in models:\n",
    "    \n",
    "        train_errors = model.model[\"train_errors\"]\n",
    "        train_line,  = plt.plot(x_train, train_errors)\n",
    "        \n",
    "        plot_colors.append(train_line.get_color())\n",
    "        \n",
    "        if train_errors.min() < min_err: \n",
    "            min_err = train_errors.min()\n",
    "        \n",
    "    # Setup yscale and vertical line:\n",
    "    my_yticks = [1]+[1/(10**i) for i in range(1,10)]\n",
    "    \n",
    "    good_yticks = np.argwhere(np.array(my_yticks) < min_err)\n",
    "    \n",
    "    if len(good_yticks) > 2:\n",
    "        my_yticks = my_yticks[:good_yticks[2][0]]\n",
    "    \n",
    "    plt.vlines(x=len(x_train), ymin=my_yticks[-1], ymax=my_yticks[0], color=\"black\",\n",
    "           linestyle=\"dashed\")\n",
    "    \n",
    "    # Plot test errors:\n",
    "    for i, model in enumerate(models):\n",
    "        \n",
    "        test_errors = model.model[\"test_errors\"]\n",
    "        test_line,  = plt.plot(x_test, test_errors,\n",
    "                               color=plot_colors[i],\n",
    "                               linestyle=\"dotted\")\n",
    "        \n",
    "        if test_errors.min() < min_err:\n",
    "            min_err = test_errors.min()\n",
    "        \n",
    "        \n",
    "    plt.xlabel(\"Time steps\", fontsize=14)\n",
    "    plt.ylabel(\"RMSE\", fontsize=14)\n",
    "    \n",
    "    plt.legend([model.name for model in models]+[\"Train-Test-Split\"],\n",
    "                fontsize=11, frameon=True, fancybox=True,\n",
    "                shadow=True, framealpha=1, facecolor=\"lightgrey\")\n",
    "    \n",
    "    \n",
    "    plt.yscale(\"log\")\n",
    "    \n",
    "    plt.yticks(my_yticks)\n",
    "    \n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35d2fa1",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea9f3bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check my_models3.py for source codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c835b9cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init was run.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "M = mm.MyModels(df, \"standard\", \"pca\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "698581dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_frac = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "29855eb3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ewoi2u3r3u94toejv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\EMILSI~1\\AppData\\Local\\Temp/ipykernel_21712/837163692.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mewoi2u3r3u94toejv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'ewoi2u3r3u94toejv' is not defined"
     ]
    }
   ],
   "source": [
    "ewoi2u3r3u94toejv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03bfaa0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_models = []\n",
    "\n",
    "baseline_models.extend([M.BaselineModel([\"z\"], \"Collective\", train_frac),\n",
    "                       M.BaselineModel([\"z\"], \"Coordinate\", train_frac),\n",
    "                       M.ReconModel([\"z\"], latent_dim=1),\n",
    "                       M.ReconModel([\"z\"], latent_dim=10),\n",
    "                       M.ReconModel([\"z\"], latent_dim=100)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcefccb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup models (with 1 latent space dimension):\n",
    "models = []\n",
    "\n",
    "for var in [\"z\"]:\n",
    "    for state_lag in range(1,4):\n",
    "        for bc in [True, False]:\n",
    "            for wind in [True, False]:\n",
    "                if wind is True or bc is True:\n",
    "                    for extra_lag in range(3):\n",
    "                        for extra_lead in range(3):\n",
    "                            models.append(\n",
    "                                M.RegressionModel(\"linear\", [var], [var], wind, bc, \n",
    "                                                  state_lag, extra_lag, extra_lead,\n",
    "                                                  latent_dim=1, train_frac=train_frac)\n",
    "                                    )\n",
    "                else:\n",
    "                    models.append(\n",
    "                                M.RegressionModel(\"linear\", [var], [var], wind, bc, \n",
    "                                                  state_lag, extra_lag, extra_lead,\n",
    "                                                  latent_dim=1, train_frac=train_frac)\n",
    "                                    )\n",
    "                    \n",
    "                    \n",
    "models_ls1 = models                               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d3117a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(models_ls1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5c60da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Setup models (with 10 latent space dimensions):\n",
    "models = []\n",
    "\n",
    "\n",
    "for var in [\"z\"]:\n",
    "    for state_lag in range(1,4):\n",
    "        for bc in [True, False]:\n",
    "            for wind in [True, False]:\n",
    "                if wind is True or bc is True:\n",
    "                    for extra_lag in range(3):\n",
    "                        for extra_lead in range(3):\n",
    "                            models.append(\n",
    "                                M.RegressionModel(\"linear\", [var], [var], wind, bc, \n",
    "                                                  state_lag, extra_lag, extra_lead,\n",
    "                                                  latent_dim=10, train_frac=train_frac)\n",
    "                                    )\n",
    "                else:\n",
    "                    models.append(\n",
    "                                M.RegressionModel(\"linear\", [var], [var], wind, bc, \n",
    "                                                  state_lag, extra_lag, extra_lead,\n",
    "                                                  latent_dim=10, train_frac=train_frac)\n",
    "                                    )\n",
    "                    \n",
    "                    \n",
    "models_ls10 = models   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6947e2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup models (with 100 latent space dimensions):\n",
    "models = []\n",
    "\n",
    "\n",
    "for var in [\"z\"]:\n",
    "    for state_lag in range(1,4):\n",
    "        for bc in [True, False]:\n",
    "            for wind in [True, False]:\n",
    "                if wind is True or bc is True:\n",
    "                    for extra_lag in range(3):\n",
    "                        for extra_lead in range(3):\n",
    "                            models.append(\n",
    "                                M.RegressionModel(\"linear\", [var], [var], wind, bc, \n",
    "                                                  state_lag, extra_lag, extra_lead,\n",
    "                                                  latent_dim=100, train_frac=train_frac)\n",
    "                                    )\n",
    "                else:\n",
    "                    models.append(\n",
    "                                M.RegressionModel(\"linear\", [var], [var], wind, bc, \n",
    "                                                  state_lag, extra_lag, extra_lead,\n",
    "                                                  latent_dim=100, train_frac=train_frac)\n",
    "                                    )\n",
    "                    \n",
    "                    \n",
    "models_ls100 = models   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5e5013",
   "metadata": {},
   "source": [
    "## Model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf1af4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dlja3wroupok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef938cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "n_models = len(baseline_models)\n",
    "\n",
    "for i, model in (enumerate(baseline_models)):\n",
    "    \n",
    "    print(f\"Running model ({i+1}/{n_models}): {model.name}\")\n",
    "    \n",
    "    model.fit().predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a31ae64",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "n_models = len(models)\n",
    "\n",
    "for i, model in (enumerate(models_ls1)):\n",
    "    \n",
    "    print(f\"Running model ({i+1}/{n_models}): {model.name}\")\n",
    "    \n",
    "    model.fit().predict()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754df96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "n_models = len(models)\n",
    "\n",
    "for i, model in (enumerate(models_ls10)):\n",
    "    \n",
    "    print(f\"Running model ({i+1}/{n_models}): {model.name}\")\n",
    "    \n",
    "    model.fit().predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b86cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "n_models = len(models)\n",
    "\n",
    "for i, model in (enumerate(models_ls100)):\n",
    "    \n",
    "    print(f\"Running model ({i+1}/{n_models}): {model.name}\")\n",
    "    \n",
    "    model.fit().predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514af191",
   "metadata": {},
   "outputs": [],
   "source": [
    "mm.Storage().latent_spaces[\"z\"]\n",
    "mm.Storage.latent_spaces[\"z\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f78868b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Checking performance of models:\n",
    "plt.figure()\n",
    "plt.title(\"Mean RMSEs of tested models with 1 dimension latent space.\")\n",
    "plt.plot(rmses_ls1, \"-o\", alpha=0.5)\n",
    "plt.yscale(\"log\")\n",
    "my_yticks = [1/(10**(i)) for i in range(0,2)] \n",
    "plt.yticks(my_yticks)\n",
    "plt.ylim(my_yticks[-1], my_yticks[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f284cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = mf.rmse(model.output_data[\"z\"], model.output_preds[\"z\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da56076a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ca07a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9df08c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc33b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "\n",
    "for var in [\"z\"]:\n",
    "    for state_lag in range(1,4):\n",
    "        for bc in [True, False]:\n",
    "            for wind in [True, False]:\n",
    "                if wind is True or bc is True:\n",
    "                    for extra_lag in range(3):\n",
    "                        for extra_lead in range(3):\n",
    "                            models.append(\n",
    "                                M.RegressionModel(\"linear\", [var], [var], wind, bc, \n",
    "                                                  state_lag, extra_lag, extra_lead,\n",
    "                                                  latent_dim=1, train_frac=train_frac)\n",
    "                                    )\n",
    "                else:\n",
    "                    models.append(\n",
    "                                M.RegressionModel(\"linear\", [var], [var], wind, bc, \n",
    "                                                  state_lag, extra_lag, extra_lead,\n",
    "                                                  latent_dim=1, train_frac=train_frac)\n",
    "                                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a3265a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "n_models = len(models)\n",
    "\n",
    "rmses_ls1 = []\n",
    "\n",
    "for i, model in (enumerate(models)):\n",
    "    \n",
    "    print(f\"Running model ({i+1}/{n_models}): {model.name}\")\n",
    "    \n",
    "    model.fit().predict()\n",
    "    \n",
    "    rmses_ls1.append(np.round(np.mean(mf.rmse(model.output_data[var], model.output_preds[var], axis=0)), 6))\n",
    "\n",
    "    \n",
    "rmses_ls1 = np.array(rmses_ls1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b960333",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121c26df",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,j in zip(range(3), range(1,4)):\n",
    "    print(i,j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7bb516",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(np.mean(mf.rmse(models[0].output_data[\"z\"], models[0].output_preds[\"z\"], axis=0)), 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b17a371",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [mm.my_models().Baseline(),\n",
    "          mm.my_models().Coordinate_Baseline(),\n",
    "          mm.my_models().PCAReconstruction(),\n",
    "          \n",
    "          mm.my_models().PCA_Multistep_Regression_Z(pca_bs = 100, pca_comps=10, ar=1),\n",
    "          mm.my_models().PCA_Multistep_Regression_BC(pca_bs = 100, pca_comps=10, ar=1),\n",
    "          mm.my_models().PCA_Multistep_Regression_Z_BC(pca_bs = 100, pca_comps=10, ar=1),\n",
    "          mm.my_models().PCA_Regression_Z_BC(pca_bs=100, pca_comps=10),\n",
    "          \n",
    "          mm.my_models().PCA_Multistep_Regression_Z(pca_bs = 100, pca_comps=10, ar=2),\n",
    "          mm.my_models().PCA_Multistep_Regression_BC(pca_bs = 100, pca_comps=10, ar=2),\n",
    "          mm.my_models().PCA_Multistep_Regression_Z_BC(pca_bs = 100, pca_comps=10, ar=2),\n",
    "          \n",
    "          mm.my_models().PCA_Multistep_Regression_Z(pca_bs=100, pca_comps=10, ar=3),\n",
    "          mm.my_models().PCA_Multistep_Regression_BC(pca_bs=100, pca_comps=10, ar=3),\n",
    "          mm.my_models().PCA_Multistep_Regression_Z_BC(pca_bs=100, pca_comps=10, ar=3),]\n",
    "          \n",
    "\n",
    "\n",
    "for model in models:\n",
    "    print(f\"Running model: {model.name}\")\n",
    "    model.run(df_train, df_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692f29af",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    model.plot_errors()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6975ba",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"Names\": [i.name for i in models],\n",
    "                   \"Avg. Train. Err.\": [i.model[\"train_errors\"].mean() for i in models],\n",
    "                   \"Avg. Train. Rank.\": np.argsort(np.argsort(np.array([i.model[\"train_errors\"].mean() for i in models]))),\n",
    "                   \"Avg. Test. Err.\": [i.model[\"test_errors\"].mean() for i in models],\n",
    "                   \"Avg. Test. Rank.\": np.argsort(np.argsort(np.array([i.model[\"test_errors\"].mean() for i in models])))})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6c8031",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "compare_models(models[-3:]+[models[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8c0af8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "compare_models(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdff85f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00603a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = mm.my_models().PCA_Multistep_Regression_BC(pca_bs=100, pca_comps=1, ar=3)\n",
    "m.run(df_train, df_test)\n",
    "m.plot_errors()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a455640",
   "metadata": {},
   "outputs": [],
   "source": [
    "m.model[\"y_train_pred\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8559249",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = mm.my_models().PCA_Multistep_Regression_BC(pca_bs=100, pca_comps=2, ar=3)\n",
    "m.run(df_train, df_test)\n",
    "m.plot_errors()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
