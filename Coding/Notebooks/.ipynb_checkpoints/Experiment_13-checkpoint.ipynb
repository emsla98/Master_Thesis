{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05bcb7e2",
   "metadata": {},
   "source": [
    "# Experiment 13: Model building using full dataset (Surface Elevation, U- and V-velocity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5106d18a",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57eec38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d668df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages:\n",
    "import mikeio\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "plt.style.use(\"seaborn-v0_8-whitegrid\")\n",
    "\n",
    "from Scripts import my_functions as mf\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA, IncrementalPCA\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "\n",
    "from IPython.display import HTML\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33dd91ef",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c93d4b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dfsu2D\n",
       "number of elements: 17980\n",
       "number of nodes: 10460\n",
       "projection: LONG/LAT\n",
       "items:\n",
       "  0:  Surface elevation <Surface Elevation> (meter)\n",
       "  1:  Total water depth <Water Depth> (meter)\n",
       "  2:  U velocity <u velocity component> (meter per sec)\n",
       "  3:  V velocity <v velocity component> (meter per sec)\n",
       "time: 18191 steps with dt=1800.0s\n",
       "      1996-12-18 00:00:00 -- 1997-12-31 23:00:00"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Find the relative path to Data/DHI_wk_sim/Area.dfsu from current directory:\n",
    "\n",
    "# Go up two levels from current directory:\n",
    "path = os.path.abspath(os.path.join(os.getcwd(), os.pardir, os.pardir))\n",
    "\n",
    "# Define path to dfsu file:\n",
    "path_area = os.path.join(path, \"Data/DHI_yr_sim/Area.dfsu\")\n",
    "\n",
    "path_wind = os.path.join(path, \"Data/DHI_yr_sim/HD_OERESUND_CREA6_1997_v2.m21fm - Result Files/wind.dfs0\")\n",
    "\n",
    "# Define paths to boundary conditions:\n",
    "path_bc_north = os.path.join(path, \"Data/DUMP/waterlevel_bc/waterlevel_north.dfs1\")\n",
    "path_bc_south = os.path.join(path, \"Data/DUMP/waterlevel_bc/waterlevel_south.dfs1\")\n",
    "\n",
    "# Open dfsu file:\n",
    "mikeio.open(path_area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df0f07fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['1996-12-18 00:00:00', '1996-12-18 00:30:00',\n",
       "               '1996-12-18 01:00:00', '1996-12-18 01:30:00',\n",
       "               '1996-12-18 02:00:00', '1996-12-18 02:30:00',\n",
       "               '1996-12-18 03:00:00', '1996-12-18 03:30:00',\n",
       "               '1996-12-18 04:00:00', '1996-12-18 04:30:00',\n",
       "               ...\n",
       "               '1997-12-31 18:30:00', '1997-12-31 19:00:00',\n",
       "               '1997-12-31 19:30:00', '1997-12-31 20:00:00',\n",
       "               '1997-12-31 20:30:00', '1997-12-31 21:00:00',\n",
       "               '1997-12-31 21:30:00', '1997-12-31 22:00:00',\n",
       "               '1997-12-31 22:30:00', '1997-12-31 23:00:00'],\n",
       "              dtype='datetime64[ns]', length=18191, freq=None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Access area data timestamps:\n",
    "area_time = mikeio.open(path_area).time\n",
    "area_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "982f09d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['1995-01-01 01:00:00', '1995-01-01 01:30:00',\n",
       "               '1995-01-01 02:00:00', '1995-01-01 02:30:00',\n",
       "               '1995-01-01 03:00:00', '1995-01-01 03:30:00',\n",
       "               '1995-01-01 04:00:00', '1995-01-01 04:30:00',\n",
       "               '1995-01-01 05:00:00', '1995-01-01 05:30:00',\n",
       "               ...\n",
       "               '2018-12-31 18:30:00', '2018-12-31 19:00:00',\n",
       "               '2018-12-31 19:30:00', '2018-12-31 20:00:00',\n",
       "               '2018-12-31 20:30:00', '2018-12-31 21:00:00',\n",
       "               '2018-12-31 21:30:00', '2018-12-31 22:00:00',\n",
       "               '2018-12-31 22:30:00', '2018-12-31 23:00:00'],\n",
       "              dtype='datetime64[ns]', length=420765, freq='1800S')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Access boundary data timestamps:\n",
    "bc_time = mikeio.open(path_bc_north).time\n",
    "bc_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca895f30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['1996-12-18 00:00:00', '1996-12-18 00:15:00',\n",
       "               '1996-12-18 00:30:00', '1996-12-18 00:45:00',\n",
       "               '1996-12-18 01:00:00', '1996-12-18 01:15:00',\n",
       "               '1996-12-18 01:30:00', '1996-12-18 01:45:00',\n",
       "               '1996-12-18 02:00:00', '1996-12-18 02:15:00',\n",
       "               ...\n",
       "               '1997-12-31 20:45:00', '1997-12-31 21:00:00',\n",
       "               '1997-12-31 21:15:00', '1997-12-31 21:30:00',\n",
       "               '1997-12-31 21:45:00', '1997-12-31 22:00:00',\n",
       "               '1997-12-31 22:15:00', '1997-12-31 22:30:00',\n",
       "               '1997-12-31 22:45:00', '1997-12-31 23:00:00'],\n",
       "              dtype='datetime64[ns]', length=36381, freq=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Access wind data timestamps:\n",
    "wind_time = mikeio.open(path_wind).time\n",
    "wind_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7e9a57",
   "metadata": {},
   "source": [
    "## Data Extraction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48e49363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 51.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "time_train = slice(\"1996-12-31\", \"1997-11-30\")\n",
    "time_test = slice(\"1997-11-30\", \"1997-12-31\")\n",
    "\n",
    "area_feats = [\"Surface elevation\", \"U velocity\", \"V velocity\"]\n",
    "area_train = mikeio.read(path_area,\n",
    "                         time=time_train,\n",
    "                         items=area_feats)\n",
    "\n",
    "area_test = mikeio.read(path_area,\n",
    "                        time=time_test,\n",
    "                        items=area_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43931ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0e47a7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Extract features from area_train:\n",
    "z_train, u_train, v_train = [area_train[area_feat].values for area_feat in area_feats]\n",
    "z_test, u_test, v_test = [area_test[area_feat].values for area_feat in area_feats]\n",
    "\n",
    "# Combine data:\n",
    "zuv_train = np.concatenate([z_train, u_train, v_train], axis=1)\n",
    "zuv_test = np.concatenate([z_test, u_test, v_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "861c78af",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data_test' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Combine data:\n",
    "zuv_train = np.concatenate([z_train, u_train, v_train], axis=1)\n",
    "\n",
    "# Extract features from data_test:\n",
    "z_data_test = data_test[\"Surface elevation\"]\n",
    "u_data_test = data_test[\"U velocity\"]\n",
    "v_data_test = data_test[\"V velocity\"]\n",
    "\n",
    "# Extract feature values:\n",
    "z_test = z_data_test.values\n",
    "u_test = u_data_test.values\n",
    "v_test = v_data_test.values\n",
    "\n",
    "# Combine data:\n",
    "zuv_test = np.concatenate([z_test, u_test, v_test], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ed0f80",
   "metadata": {},
   "source": [
    "### PCA and scalers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29ff4f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute = 0\n"
     ]
    }
   ],
   "source": [
    "# Auxilliary variable:\n",
    "compute = 1\n",
    "\n",
    "# Try to load results from earlier runs:\n",
    "if 1:\n",
    "    \n",
    "    # Load scaler and pca if they exist:\n",
    "    if os.path.exists(\"../Data_Results/Exp_13_scaler.pkl\") and \\\n",
    "       os.path.exists(\"../Data_Results/Exp_13_pca.pkl\"):\n",
    "        \n",
    "        # Load scaler:\n",
    "        with open(\"../Data_Results/Exp_13_scaler.pkl\", \"rb\") as f:\n",
    "            scaler = pkl.load(f)\n",
    "            \n",
    "        # Load pca:\n",
    "        with open(\"../Data_Results/Exp_13_pca.pkl\", \"rb\") as f:\n",
    "            ipca = pkl.load(f)\n",
    "        \n",
    "        \n",
    "        # Change compute to 0:\n",
    "        compute = 0\n",
    "        \n",
    "print(f\"compute = {compute}\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "facdd894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Fit scaler for training data: (1.5 min)\n",
    "if compute:\n",
    "    \n",
    "    # Fit scaler:\n",
    "    scaler = StandardScaler().fit(zuv_train)\n",
    "    \n",
    "    # Transform features:\n",
    "    zuv_train_scaled = scaler.transform(zuv_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c868f784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Fit pca for scaled training data: (~ 9 min)\n",
    "if compute:\n",
    "    \n",
    "    # Fit IncrementalPCA:\n",
    "    ipca = IncrementalPCA(batch_size=250)\n",
    "    \n",
    "    # Partially fit every 250 samples:\n",
    "    for i in tqdm(range(0, zuv_train_scaled.shape[0], 250)[:-1]):\n",
    "        ipca.partial_fit(zuv_train_scaled[i:i+250, :])\n",
    "\n",
    "    # Fit the remaining samples:\n",
    "    ipca.partial_fit(zuv_train_scaled[i+250:, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "01564ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "# Save scaler and ipca objects (in Coding/Data_Results):\n",
    "if compute:\n",
    "    \n",
    "    # Save scaler:\n",
    "    with open(\"../Data_Results/Exp_13_scaler.pkl\", \"wb\") as f:\n",
    "        pkl.dump(scaler, f)\n",
    "    \n",
    "    # Save pca:\n",
    "    with open(\"../Data_Results/Exp_13_pca.pkl\", \"wb\") as f:\n",
    "        pkl.dump(ipca, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1595441b",
   "metadata": {},
   "source": [
    "#### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8acc7f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Super class for models:\n",
    "class myModels():\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    # Templates:\n",
    "    class ModelTemplate:\n",
    "        \"\"\"\n",
    "        Ensures that the methods fit, predict, and fit_predict are \n",
    "        instantiated for all classes based on this template.\n",
    "        \"\"\"\n",
    "\n",
    "        def fit(self, X, y=None):\n",
    "            raise NotImplementedError(\"fit method must be implemented in subclass\")\n",
    "\n",
    "        def predict(self, X, y=None):\n",
    "            raise NotImplementedError(\"predict method must be implemented in subclass\")\n",
    "\n",
    "        def fit_predict(self, X, y=None):\n",
    "            self.fit(X, y)\n",
    "            return self.predict(X, y)\n",
    "\n",
    "\n",
    "    class IPCA(ModelTemplate):\n",
    "\n",
    "        def __init__(self, n_components=None):\n",
    "            self.n_components = n_components\n",
    "            self.model = IncrementalPCA(n_components=self.n_components,\n",
    "                                        batch_size=self.n_components)\n",
    "\n",
    "        def fit(self, X, y=None):\n",
    "            self.model.fit(X, y)\n",
    "            return self\n",
    "\n",
    "        def predict(self, X):\n",
    "            X = self.model.transform(X)\n",
    "            return self.model.inverse_transform(X)\n",
    "\n",
    "\n",
    "    class PCA(ModelTemplate):\n",
    "        \n",
    "        def __init__(self, n_components=None):\n",
    "            self.n_components = n_components\n",
    "            self.model = PCA(n_components=self.n_components)\n",
    "\n",
    "        def fit(self, X, y=None):\n",
    "            self.model.fit(X, y)\n",
    "            return self\n",
    "\n",
    "        def predict(self, X):\n",
    "            X = self.model.transform(X)\n",
    "            return self.model.inverse_transform(X)\n",
    "\n",
    "    \n",
    "    class Baseline(ModelTemplate):\n",
    "        \n",
    "        def __init__(self):\n",
    "            pass\n",
    "        \n",
    "        def fit(self, X, y=None):\n",
    "            self.mean = np.mean(X)\n",
    "            return self\n",
    "        \n",
    "        def predict(self, X, y=None):\n",
    "            if y is None:\n",
    "                self.shape = X.shape\n",
    "            else:\n",
    "                self.shape = y.shape\n",
    "            \n",
    "            pred = np.tile(self.mean, self.shape)\n",
    "            return pred\n",
    "            \n",
    "    \n",
    "    class BaselineCoordinate(ModelTemplate):\n",
    "        \n",
    "        def __init__(self):\n",
    "            pass\n",
    "        \n",
    "        def fit(self, X, y=None):\n",
    "            self.mean = np.mean(X, axis=0)\n",
    "            return self\n",
    "        \n",
    "        def predict(self, X, y=None):\n",
    "            \n",
    "            if y is None:\n",
    "                self.shape = X.shape\n",
    "            else:\n",
    "                self.shape = y.shape\n",
    "                \n",
    "            pred = np.tile(self.mean, [self.shape[0], 1])\n",
    "            return pred\n",
    "        \n",
    "    \n",
    "    class PCABaseline(ModelTemplate):\n",
    "        \n",
    "        def __init__(self, pcs=None):\n",
    "            \n",
    "            # Load the PCA and scaler:\n",
    "            with open(\"../Data_Results/Exp_13_pca.pkl\", \"rb\") as f:\n",
    "                ipca = pkl.load(f)\n",
    "                \n",
    "            with open(\"../Data_Results/Exp_13_scaler.pkl\", \"rb\") as f:\n",
    "                scaler = pkl.load(f)\n",
    "            \n",
    "            # Define parameters\n",
    "            self.pca = ipca\n",
    "            if pcs is None:\n",
    "                self.pcs = (ipca.explained_variance_ > 1).sum()\n",
    "            self.pca_mat = ipca.components_[:self.pcs]\n",
    "            self.scaler = scaler\n",
    "            \n",
    "            \n",
    "        def fit(self, X, y=None):\n",
    "            \n",
    "            # Scale:\n",
    "            X_scaled = self.scaler.transform(X)\n",
    "            \n",
    "            # Transform:\n",
    "            X_scaled_pca = X_scaled @ self.pca_mat.T\n",
    "            \n",
    "            # Mean:\n",
    "            X_scaled_pca_mean = X_scaled_pca[0].reshape(1,-1) * 0 \\\n",
    "                                + np.mean(X_scaled_pca)\n",
    "            \n",
    "            # Re-transform\n",
    "            X_scaled_mean = X_scaled_pca_mean @ self.pca_mat\n",
    "            \n",
    "            # Re-scale:\n",
    "            X_mean = self.scaler.inverse_transform(X_scaled_mean)\n",
    "\n",
    "            self.mean = X_mean\n",
    "            \n",
    "            return self\n",
    "        \n",
    "        def predict(self, X, y=None):\n",
    "            if y is None:\n",
    "                self.shape = X.shape\n",
    "            else:\n",
    "                self.shape = y.shape\n",
    "            \n",
    "            pred = np.tile(self.mean, (self.shape[0], 1))\n",
    "            return pred\n",
    "        \n",
    "    \n",
    "    class PCABaselineCoordinate(ModelTemplate):\n",
    "        \n",
    "        def __init__(self, pcs=None):\n",
    "            \n",
    "            # Load the PCA and scaler:\n",
    "            with open(\"../Data_Results/Exp_13_pca.pkl\", \"rb\") as f:\n",
    "                ipca = pkl.load(f)\n",
    "                \n",
    "            with open(\"../Data_Results/Exp_13_scaler.pkl\", \"rb\") as f:\n",
    "                scaler = pkl.load(f)\n",
    "            \n",
    "            # Define parameters\n",
    "            self.pca = ipca\n",
    "            if pcs is None:\n",
    "                self.pcs = (ipca.explained_variance_ > 1).sum()\n",
    "            self.pca_mat = ipca.components_[:self.pcs]\n",
    "            self.scaler = scaler\n",
    "            \n",
    "            \n",
    "        def fit(self, X, y=None):\n",
    "            \n",
    "            # Scale:\n",
    "            X_scaled = self.scaler.transform(X)\n",
    "            \n",
    "            # Transform:\n",
    "            X_scaled_pca = X_scaled @ self.pca_mat.T\n",
    "            \n",
    "            # Mean:\n",
    "            X_scaled_pca_mean = X_scaled_pca[0].reshape(1,-1) * 0 \\\n",
    "                                + np.mean(X_scaled_pca, axis=0).reshape(1,-1)\n",
    "            \n",
    "            # Re-transform\n",
    "            X_scaled_mean = X_scaled_pca_mean @ self.pca_mat\n",
    "            \n",
    "            # Re-scale:\n",
    "            X_mean = self.scaler.inverse_transform(X_scaled_mean)\n",
    "\n",
    "            self.mean = X_mean\n",
    "            \n",
    "            return self\n",
    "        \n",
    "        def predict(self, X, y=None):\n",
    "            if y is None:\n",
    "                self.shape = X.shape\n",
    "            else:\n",
    "                self.shape = y.shape\n",
    "            \n",
    "            pred = np.tile(self.mean, (self.shape[0], 1))\n",
    "            return pred\n",
    "            \n",
    "            \n",
    "            \n",
    "    class PCALinearRegression(ModelTemplate):\n",
    "        \n",
    "        def __init__(self, pcs=None):\n",
    "            \n",
    "            # Load the PCA and scaler:\n",
    "            with open(\"../Data_Results/Exp_13_pca.pkl\", \"rb\") as f:\n",
    "                ipca = pkl.load(f)\n",
    "                \n",
    "            with open(\"../Data_Results/Exp_13_scaler.pkl\", \"rb\") as f:\n",
    "                scaler = pkl.load(f)\n",
    "            \n",
    "            # Define parameters\n",
    "            self.pca = ipca\n",
    "            \n",
    "            if pcs is not None:\n",
    "                self.pcs = pcs\n",
    "            else:\n",
    "                self.pcs = (ipca.explained_variance_ > 1).sum()\n",
    "                \n",
    "            self.pca_mat = ipca.components_[:self.pcs]\n",
    "            self.scaler = scaler\n",
    "            \n",
    "            \n",
    "        def fit(self, X, y=None):\n",
    "            \n",
    "            scaler = self.scaler\n",
    "            pca_mat = self.pca_mat\n",
    "            \n",
    "            # Scale:\n",
    "            X_scaled = scaler.transform(X)\n",
    "            \n",
    "            # Transform:\n",
    "            X_scaled_pca = X_scaled @ pca_mat.T\n",
    "            \n",
    "            # Extract in- and output for linear regression:\n",
    "            X_scaled_pca_in = X_scaled_pca[:-1]\n",
    "            X_scaled_pca_out = X_scaled_pca[1:]\n",
    "            \n",
    "            # Fit linear model:\n",
    "            LR = LinearRegression()\n",
    "            LR.fit(X_scaled_pca_in, X_scaled_pca_out)\n",
    "            \n",
    "            self.LR = LR\n",
    "            \n",
    "            return self\n",
    "        \n",
    "        def predict(self, X, y=None):\n",
    "            \n",
    "            pcs     = self.pcs\n",
    "            scaler  = self.scaler\n",
    "            pca_mat = self.pca_mat\n",
    "            LR      = self.LR\n",
    "            \n",
    "            if y is None:\n",
    "                pred_shape = (len(X), pcs)\n",
    "            else:\n",
    "                pred_shape = (len(y), pcs)\n",
    "            \n",
    "            pred_scaled_pca = np.zeros(pred_shape)\n",
    "            \n",
    "            # Fill pred with predictions:\n",
    "            for i in range(len(pred_scaled_pca)):\n",
    "                \n",
    "                if i == 0:\n",
    "                    X_last = X[-1].reshape(1,-1)\n",
    "                    X_last_scaled = scaler.transform(X_last)\n",
    "                    X_last_scaled_pca = (X_last_scaled @ pca_mat.T).reshape(1,-1)\n",
    "                    pred_scaled_pca[i] = LR.predict(X=X_last_scaled_pca).reshape(-1)\n",
    "                else:\n",
    "                    pred_scaled_pca[i] = LR.predict(X=pred_scaled_pca[i-1].reshape(1,-1))\n",
    "            \n",
    "            pred_scaled = pred_scaled_pca @ pca_mat\n",
    "            pred = scaler.inverse_transform(pred_scaled)\n",
    "            \n",
    "            return pred\n",
    "        \n",
    "        \n",
    "    class PCALinearRegressionBC(ModelTemplate):\n",
    "        \n",
    "        def __init__(self, pcs=None):\n",
    "            \n",
    "            # Load the PCA and scaler:\n",
    "            with open(\"../Data_Results/Exp_13_pca.pkl\", \"rb\") as f:\n",
    "                ipca = pkl.load(f)\n",
    "                \n",
    "            with open(\"../Data_Results/Exp_13_scaler.pkl\", \"rb\") as f:\n",
    "                scaler = pkl.load(f)\n",
    "            \n",
    "            # Load boundary conditions:\n",
    "            bc_north_train = mikeio.read(path_bc_north,\n",
    "                                         time=time_train)[0].values\n",
    "            bc_south_train = mikeio.read(path_bc_south, \n",
    "                                         time=time_train)[0].values\n",
    "            \n",
    "            self.bc_train = np.concatenate([bc_north_train, bc_south_train], axis=1)\n",
    "            \n",
    "            bc_north_test = mikeio.read(path_bc_north,\n",
    "                                        time=time_test)[0].values\n",
    "            bc_south_test = mikeio.read(path_bc_south,\n",
    "                                        time=time_test)[0].values\n",
    "            \n",
    "            self.bc_test = np.concatenate([bc_north_test, bc_south_test], axis=1)\n",
    "            \n",
    "            # Define parameters\n",
    "            self.pca = ipca\n",
    "            \n",
    "            if pcs is not None:\n",
    "                self.pcs = pcs\n",
    "            else:\n",
    "                self.pcs = (ipca.explained_variance_ > 1).sum()\n",
    "                \n",
    "            self.pca_mat = ipca.components_[:self.pcs]\n",
    "            self.scaler = scaler\n",
    "            \n",
    "            \n",
    "        def fit(self, X, y=None):\n",
    "            \n",
    "            scaler = self.scaler\n",
    "            pca_mat = self.pca_mat\n",
    "            bc_train = self.bc_train[:len(X)]\n",
    "            \n",
    "            # Scale:\n",
    "            X_scaled = scaler.transform(X)\n",
    "            \n",
    "            # Transform:\n",
    "            X_scaled_pca = X_scaled @ pca_mat.T\n",
    "            \n",
    "            # Extract in- and output for linear regression:\n",
    "            X_scaled_pca_in = X_scaled_pca[:-1]\n",
    "            X_scaled_pca_out = X_scaled_pca[1:]\n",
    "            \n",
    "            X_in = np.concatenate([X_scaled_pca_in, bc_train[:-1]], axis=1)\n",
    "            \n",
    "            # Fit linear model:\n",
    "            LR = LinearRegression()\n",
    "            LR.fit(X_in, X_scaled_pca_out)\n",
    "            \n",
    "            self.LR = LR\n",
    "            \n",
    "            return self\n",
    "        \n",
    "        def predict(self, X, y=None):\n",
    "            \n",
    "            pcs     = self.pcs\n",
    "            scaler  = self.scaler\n",
    "            pca_mat = self.pca_mat\n",
    "            LR      = self.LR\n",
    "            bc_test = self.bc_test\n",
    "            \n",
    "            if y is None:\n",
    "                pred_shape = (len(X), pcs)\n",
    "            else:\n",
    "                pred_shape = (len(y), pcs)\n",
    "            \n",
    "            pred_scaled_pca = np.zeros(pred_shape)\n",
    "            \n",
    "            # Fill pred with predictions:\n",
    "            for i in range(len(pred_scaled_pca)):\n",
    "                \n",
    "                if i == 0:\n",
    "                    X_last = X[-1].reshape(1,-1)\n",
    "                    X_last_scaled = scaler.transform(X_last)\n",
    "                    X_last_scaled_pca = (X_last_scaled @ pca_mat.T).reshape(1,-1)\n",
    "                    \n",
    "                    X_in = np.concatenate([X_last_scaled_pca, \n",
    "                                           bc_test[i].reshape(1,-1)], axis=1)\n",
    "                    \n",
    "                    pred_scaled_pca[i] = LR.predict(X=X_in).reshape(-1)\n",
    "                else:\n",
    "                    X_in = np.concatenate([pred_scaled_pca[i-1].reshape(1,-1), \n",
    "                                           bc_test[i].reshape(1,-1)], axis=1)\n",
    "                    \n",
    "                    pred_scaled_pca[i] = LR.predict(X_in).reshape(-1)\n",
    "            \n",
    "            pred_scaled = pred_scaled_pca @ pca_mat\n",
    "            pred = scaler.inverse_transform(pred_scaled)\n",
    "            \n",
    "            return pred\n",
    "        \n",
    "    \n",
    "    \n",
    "        \n",
    "    class PCARidgeRegression(ModelTemplate):\n",
    "        \n",
    "        def __init__(self, alpha=1, pcs=None):\n",
    "            \n",
    "            # Load the PCA and scaler:\n",
    "            with open(\"../Data_Results/Exp_13_pca.pkl\", \"rb\") as f:\n",
    "                ipca = pkl.load(f)\n",
    "                \n",
    "            with open(\"../Data_Results/Exp_13_scaler.pkl\", \"rb\") as f:\n",
    "                scaler = pkl.load(f)\n",
    "            \n",
    "            # Define parameters\n",
    "            self.pca = ipca\n",
    "            \n",
    "            if pcs is not None:\n",
    "                self.pcs = pcs\n",
    "            else:\n",
    "                self.pcs = (ipca.explained_variance_ > 1).sum()\n",
    "                \n",
    "            self.pca_mat = ipca.components_[:self.pcs]\n",
    "            self.scaler = scaler\n",
    "            self.alpha = alpha\n",
    "    \n",
    "            \n",
    "        def fit(self, X, y=None):\n",
    "            \n",
    "            scaler = self.scaler\n",
    "            pca_mat = self.pca_mat\n",
    "            alpha = self.alpha\n",
    "            \n",
    "            # Scale:\n",
    "            X_scaled = scaler.transform(X)\n",
    "            \n",
    "            # Transform:\n",
    "            X_scaled_pca = X_scaled @ pca_mat.T\n",
    "            \n",
    "            # Extract in- and output for linear regression:\n",
    "            X_scaled_pca_in = X_scaled_pca[:-1]\n",
    "            X_scaled_pca_out = X_scaled_pca[1:]\n",
    "            \n",
    "            # Fit linear model:\n",
    "            LR = Ridge(alpha=alpha)\n",
    "            LR.fit(X_scaled_pca_in, X_scaled_pca_out)\n",
    "            \n",
    "            self.LR = LR\n",
    "            \n",
    "            return self\n",
    "        \n",
    "        def predict(self, X, y=None):\n",
    "            \n",
    "            pcs     = self.pcs\n",
    "            scaler  = self.scaler\n",
    "            pca_mat = self.pca_mat\n",
    "            LR      = self.LR\n",
    "            \n",
    "            if y is None:\n",
    "                pred_shape = (len(X), pcs)\n",
    "            else:\n",
    "                pred_shape = (len(y), pcs)\n",
    "            \n",
    "            pred_scaled_pca = np.zeros(pred_shape)\n",
    "            \n",
    "            # Fill pred with predictions:\n",
    "            for i in range(len(pred_scaled_pca)):\n",
    "                \n",
    "                if i == 0:\n",
    "                    X_last = X[-1].reshape(1,-1)\n",
    "                    X_last_scaled = scaler.transform(X_last)\n",
    "                    X_last_scaled_pca = (X_last_scaled @ pca_mat.T).reshape(1,-1)\n",
    "                    pred_scaled_pca[i] = LR.predict(X=X_last_scaled_pca).reshape(-1)\n",
    "                else:\n",
    "                    pred_scaled_pca[i] = LR.predict(X=pred_scaled_pca[i-1].reshape(1,-1))\n",
    "            \n",
    "            pred_scaled = pred_scaled_pca @ pca_mat\n",
    "            pred = scaler.inverse_transform(pred_scaled)\n",
    "            \n",
    "            return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c843d33b",
   "metadata": {},
   "source": [
    "#### Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0900fa0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of models:\n",
    "models = [myModels.Baseline(),\n",
    "          myModels.BaselineCoordinate(),\n",
    "          myModels.PCABaseline(),\n",
    "          myModels.PCABaselineCoordinate(),\n",
    "          myModels.PCALinearRegression(),\n",
    "          myModels.PCARidgeRegression(alpha=1),\n",
    "          myModels.PCARidgeRegression(alpha=10),\n",
    "          myModels.PCALinearRegressionBC()\n",
    "         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "cff41bee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16080"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(zuv_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d37dd393",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|██████████████████████████████████████████                                          | 4/8 [00:00<00:00, 32.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 53940)\n",
      "(10, 53940)\n",
      "(10, 53940)\n",
      "(10, 53940)\n",
      "(10, 53940)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 19.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 53940)\n",
      "(10, 53940)\n",
      "(10, 53940)\n",
      "\n",
      "All models are working\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Ensure that models compute:\n",
    "for model in tqdm(models):\n",
    "    print(model.fit_predict(zuv_train[:20], zuv_test[:10]).shape)\n",
    "\n",
    "print(\"\\nAll models are working\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f798bd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method for evaluating models:\n",
    "def eval_models(models, train_data, test_data):\n",
    "    \"\"\"\n",
    "    Tests multiple models by computing the RMSE of the model prediction for training and test datasets.\n",
    "    ---\n",
    "    Parameters:\n",
    "    models: list (k)\n",
    "    train_data: array (m1 x n)\n",
    "    test_data: array (m2 x n)\n",
    "    \n",
    "    return: dataframe (k x 5)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Allocate:\n",
    "    model_names = []; train_rmses = []; test_rmses = [] \n",
    "    \n",
    "    # Loop over models:\n",
    "    for model in tqdm(models):\n",
    "        \n",
    "        # Fit model:\n",
    "        model.fit(train_data)\n",
    "        \n",
    "        # Predict:\n",
    "        pred_train = model.predict(train_data)\n",
    "        pred_test = model.predict(test_data)\n",
    "        \n",
    "        # Compute errors: (Consider whether this is right way to compute errors)\n",
    "        error_train = mf.rmse(pred_train, train_data, axis=1).mean()\n",
    "        error_test = mf.rmse(pred_test, test_data, axis=1).mean()\n",
    "        \n",
    "        # Extract model name:\n",
    "        model_name = type(model).__name__\n",
    "        \n",
    "        # Append to lists:\n",
    "        model_names.append(model_name)\n",
    "        train_rmses.append(error_train)\n",
    "        test_rmses.append(error_test)\n",
    "    \n",
    "    # Transform to numpy arrays:\n",
    "    train_rmses = np.array(train_rmses)\n",
    "    test_rmses = np.array(test_rmses)\n",
    "    \n",
    "    # Compute model rankings:\n",
    "    train_rmses_rank = np.argsort(np.argsort(train_rmses))\n",
    "    test_rmses_rank = np.argsort(np.argsort(test_rmses))\n",
    "    \n",
    "    # Create dataframe:\n",
    "    rmses = pd.DataFrame({\n",
    "                \"Model\": model_names,\n",
    "                \"Train RMSE\": train_rmses,\n",
    "                \"Test RMSE\": test_rmses,\n",
    "                \"Train Rank\": train_rmses_rank,\n",
    "                \"Test Rank\": test_rmses_rank})\n",
    "\n",
    "    return rmses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "657c4c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [01:01<00:00,  7.72s/it]\n"
     ]
    }
   ],
   "source": [
    "# Sample training data:\n",
    "train_sample = np.linspace(0, len(zuv_train)-1, 48, dtype=int)\n",
    "\n",
    "rmses = eval_models(models, zuv_train[:len(zuv_test)], zuv_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7b2d9aed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train RMSE</th>\n",
       "      <th>Test RMSE</th>\n",
       "      <th>Train Rank</th>\n",
       "      <th>Test Rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>1.236441e-01</td>\n",
       "      <td>1.274815e-01</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BaselineCoordinate</td>\n",
       "      <td>1.157003e-01</td>\n",
       "      <td>1.198514e-01</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PCABaseline</td>\n",
       "      <td>1.296251e-01</td>\n",
       "      <td>1.292335e-01</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PCABaselineCoordinate</td>\n",
       "      <td>1.157004e-01</td>\n",
       "      <td>1.198508e-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PCALinearRegression</td>\n",
       "      <td>2.463271e-01</td>\n",
       "      <td>1.416224e-01</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PCARidgeRegression</td>\n",
       "      <td>2.003376e-01</td>\n",
       "      <td>1.345763e-01</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PCARidgeRegression</td>\n",
       "      <td>1.345303e-01</td>\n",
       "      <td>1.231889e-01</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PCALinearRegressionBC</td>\n",
       "      <td>9.284959e+113</td>\n",
       "      <td>5.244289e+113</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model     Train RMSE      Test RMSE  Train Rank  Test Rank\n",
       "0               Baseline   1.236441e-01   1.274815e-01           2          3\n",
       "1     BaselineCoordinate   1.157003e-01   1.198514e-01           0          1\n",
       "2            PCABaseline   1.296251e-01   1.292335e-01           3          4\n",
       "3  PCABaselineCoordinate   1.157004e-01   1.198508e-01           1          0\n",
       "4    PCALinearRegression   2.463271e-01   1.416224e-01           6          6\n",
       "5     PCARidgeRegression   2.003376e-01   1.345763e-01           5          5\n",
       "6     PCARidgeRegression   1.345303e-01   1.231889e-01           4          2\n",
       "7  PCALinearRegressionBC  9.284959e+113  5.244289e+113           7          7"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323fa0fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
