{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 15: Pipeline for model building, training, parameter optimization, and evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import mikeio\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import pickle as pkl\n",
    "import dill\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import re\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "plt.style.use(\"seaborn-v0_8-whitegrid\")\n",
    "\n",
    "from Scripts import my_functions as mf, my_models as mm\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.linear_model import LinearRegression, SGDRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import IncrementalPCA\n",
    "from sklearn.model_selection import TimeSeriesSplit, RandomizedSearchCV, GridSearchCV, train_test_split, cross_val_score, cross_validate\n",
    "\n",
    "from xgboost import XGBRegressor as XGBR\n",
    "\n",
    "from IPython.display import HTML\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data from memory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auxilliary variable:\n",
    "compute = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute = 0\n",
      "Wall time: 9.17 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "# Try to load results from earlier runs:\n",
    "if compute:\n",
    "    \n",
    "    # Load combined data if available:\n",
    "    if os.path.exists(\"../../Data/my_data/data.pkl\"):\n",
    "        \n",
    "        # Load dataframe:\n",
    "        with open(\"../../Data/my_data/data.pkl\", \"rb\") as f:\n",
    "            df_full = dill.load(f)\n",
    "            \n",
    "        # Change compute to 0:\n",
    "        compute = 0\n",
    "        \n",
    "print(f\"compute = {compute}\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18143, 54004)\n"
     ]
    }
   ],
   "source": [
    "print(df_full.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 54004)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Isolate small part of data:\n",
    "df = df_full.iloc[:100,]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storage class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Storage class that holds useful functions and variables:\n",
    "class Storage:\n",
    "\n",
    "    \"\"\"Class for storing data and functions.\"\"\"\n",
    "\n",
    "    # Method for initializing:\n",
    "    def __init__(self):\n",
    "\n",
    "        self.data = {}\n",
    "        self.scalers = {}\n",
    "        self.projectors = {}\n",
    "\n",
    "        self.n_every = 10\n",
    "        self.scalers_fitted = False\n",
    "\n",
    "        self.max_dim = min(500, len(df) // self.n_every)\n",
    "        self.bat_size = 512\n",
    "\n",
    "        self.debug = False\n",
    "\n",
    "    # Method for loading data into storage:    \n",
    "    def load_data(self, dataframe):\n",
    "\n",
    "        \"\"\"Loads data from dataframe into dictionary of dataframes.\"\"\"\n",
    "\n",
    "        # Rename:\n",
    "        df = dataframe\n",
    "            \n",
    "        # Dictionary w/ variables and regexes:\n",
    "        my_var_dict = {\"z\"   : \"z_\", \n",
    "                        \"u\"   : \"^u_\",\n",
    "                        \"v\"   : \"^v_\",\n",
    "                        \"bcn\" : \"bcn_\",\n",
    "                        \"bcs\" : \"bcs_\",\n",
    "                        \"wu\"  : \"wu_\",\n",
    "                        \"wv\"  : \"wv_\"}\n",
    "\n",
    "        # Loop over variables:\n",
    "        for key, regex in my_var_dict.items():\n",
    "\n",
    "            # Filter:\n",
    "            df_temp = df.filter(regex=regex)\n",
    "\n",
    "            # Store:\n",
    "            self.data[key] = df_temp\n",
    "\n",
    "        # Return:\n",
    "        return \n",
    "\n",
    "    # Method for fetching data from storage:\n",
    "    def get_data(self, variables):\n",
    "\n",
    "        \"\"\"Fetches dictionaries corresponding to variables.\"\"\"\n",
    "            \n",
    "        # Initialize:\n",
    "        data = {}\n",
    "\n",
    "        # Loop over variables:\n",
    "        for key in variables:\n",
    "\n",
    "            # Store:\n",
    "            data[key] = self.data[key]\n",
    "\n",
    "        # Return:\n",
    "        return data\n",
    "\n",
    "    # Method for loading scalers:\n",
    "    def load_scalers(self, scaler, variables):\n",
    "        \n",
    "        \"\"\"Loads scalers for each variable.\"\"\"\n",
    "            \n",
    "        # Loop over variables:\n",
    "        for key in variables:\n",
    "            \n",
    "            # Store:\n",
    "            self.scalers[key] = scaler\n",
    "\n",
    "        # Return:\n",
    "        return\n",
    "\n",
    "    # Method for loading projectors:\n",
    "    def load_projectors(self, projector, variables):\n",
    "        \n",
    "        \"\"\"Loads projectors for each variable.\"\"\"\n",
    "        \n",
    "        # Set max dimensions:\n",
    "        projector.n_components = self.max_dim\n",
    "\n",
    "        # Loop over variables:\n",
    "        for key in variables:\n",
    "            \n",
    "            # Store:\n",
    "            self.projectors[key] = projector\n",
    "            \n",
    "        # Return:\n",
    "        return\n",
    "\n",
    "    # Method for fetching scalers:\n",
    "    def get_scalers(self, variables):\n",
    "        \n",
    "        \"\"\"Fetches dictionaries corresponding to variables.\"\"\"\n",
    "            \n",
    "        # Initialize:\n",
    "        scalers = {}\n",
    "\n",
    "        # Loop over variables:\n",
    "        for key in variables:\n",
    "\n",
    "            # Store:\n",
    "            scalers[key] = self.scalers[key]\n",
    "\n",
    "        # Return:\n",
    "        return scalers\n",
    "\n",
    "    # Method for fetching projectors:\n",
    "    def get_projectors(self, variables):\n",
    "        \n",
    "        \"\"\"Fetches dictionaries corresponding to variables.\"\"\"\n",
    "            \n",
    "        # Initialize:\n",
    "        projectors = {}\n",
    "\n",
    "        # Loop over variables:\n",
    "        for key in variables:\n",
    "\n",
    "            # Store:\n",
    "            projectors[key] = self.projectors[key]\n",
    "\n",
    "        # Return:\n",
    "        return projectors\n",
    "\n",
    "    # Method for fitting scalers:\n",
    "    def fit_scalers(self, variables):\n",
    "            \n",
    "        \"\"\"Fits scalers for each variable.\"\"\"\n",
    "        \n",
    "        # Initialize:\n",
    "        fit_data = None\n",
    "\n",
    "        # Loop over variables:\n",
    "        for key in variables:\n",
    "            \n",
    "            # Use subset of data:\n",
    "            fit_data = self.data[key].iloc[::self.n_every].values\n",
    "\n",
    "            # Fit:\n",
    "            self.scalers[key].fit(fit_data)\n",
    "        \n",
    "        # Set flag:\n",
    "        self.scalers_fitted = True\n",
    "\n",
    "        # Return:\n",
    "        return\n",
    "\n",
    "    # Method for fitting projectors:\n",
    "    def fit_projectors(self, variables):\n",
    "            \n",
    "        \"\"\"Fits projectors for each variable.\"\"\"\n",
    "        \n",
    "        # Initialize:\n",
    "        fit_data = None\n",
    "\n",
    "        # Loop over variables:\n",
    "        for key in variables:\n",
    "            \n",
    "            # Use subset of data:\n",
    "            fit_data = self.data[key].iloc[::self.n_every].values\n",
    "\n",
    "            # Check if scalers have been fitted:\n",
    "            if self.scalers_fitted:\n",
    "                    \n",
    "                # Transform:\n",
    "                fit_data = self.scalers[key].transform(fit_data)\n",
    "\n",
    "            # Fit:\n",
    "            self.projectors[key].fit(fit_data)\n",
    "        \n",
    "        # Return:\n",
    "        return\n",
    "\n",
    "    # Method for converting dictionary of dataframes into dataframe:\n",
    "    def dicts2df(self, data, variables):\n",
    "                \n",
    "            \"\"\"Converts dictionary of dataframes into dataframe.\"\"\"\n",
    "            \n",
    "            # Initialize:\n",
    "            df = None\n",
    "            df_list = []\n",
    "    \n",
    "            # Loop over variables:\n",
    "            for key in variables:\n",
    "                \n",
    "                # Append:\n",
    "                df_list.append(data[key])\n",
    "\n",
    "            # Concatenate:\n",
    "            df = pd.concat(df_list, axis=1)\n",
    "\n",
    "            # Return:\n",
    "            return df\n",
    "\n",
    "    # Method for converting dataframe into dictionary of dataframes:\n",
    "    def df2dicts(self, data, variables):\n",
    "            \n",
    "        \"\"\"Recovers dictionary of dataframes from data.\"\"\"\n",
    "        \n",
    "        # Initialize:\n",
    "        reconverted_data = {}\n",
    "\n",
    "        if variables is None:\n",
    "            return None\n",
    "\n",
    "        # Loop over variables:\n",
    "        for key in variables:\n",
    "            \n",
    "            # Filter dataframe:\n",
    "            data_tmp = data.filter(regex=f\"^{key}\")\n",
    "\n",
    "            # Overwrite\n",
    "            reconverted_data[key] = data_tmp\n",
    "\n",
    "        # Return:\n",
    "        return reconverted_data\n",
    "    \n",
    "    # Method for scaling data:\n",
    "    def scale_data(self, direction, data, variables):\n",
    "            \n",
    "        \"\"\"Scales data for each variable.\"\"\"\n",
    "        \n",
    "        # Initialize:\n",
    "        scaled_data = {}\n",
    "        data_tmp = None\n",
    "\n",
    "        # Loop over variables:\n",
    "        for key in variables:\n",
    "\n",
    "            indices = data[key].index\n",
    "\n",
    "            if direction == \"forward\":\n",
    "                \n",
    "                # Transform:\n",
    "                data_tmp = self.scalers[key].transform(data[key])\n",
    "\n",
    "            if direction == \"backward\":\n",
    "                \n",
    "                # Inverse transform:\n",
    "                data_tmp = self.scalers[key].inverse_transform(data[key])\n",
    "\n",
    "            # Get shape:\n",
    "            h, w = data_tmp.shape\n",
    "            \n",
    "            # Overwrite:\n",
    "            scaled_data[key] = self.data[key].iloc[:h, :w].copy()\n",
    "\n",
    "            scaled_data[key].iloc[:, :] = data_tmp\n",
    "\n",
    "            scaled_data[key].index = indices\n",
    "\n",
    "        # Return:\n",
    "        return scaled_data\n",
    "    \n",
    "    # Method for projecting data:\n",
    "    def project_data(self, direction, data, variables):\n",
    "            \n",
    "        \"\"\"Projects data for each variable.\"\"\"\n",
    "        \n",
    "        # Initialize:\n",
    "        projected_data = {}\n",
    "        data_tmp = {}\n",
    "\n",
    "        # Loop over variables:\n",
    "        for key in variables:\n",
    "            \n",
    "            indices = data[key].index\n",
    "\n",
    "            if direction == \"forward\":\n",
    "                \n",
    "                # Transform:\n",
    "                data_tmp = self.projectors[key].transform(data[key])\n",
    "\n",
    "            if direction == \"backward\":\n",
    "                \n",
    "                # Inverse transform:\n",
    "                data_tmp = self.projectors[key].inverse_transform(data[key])\n",
    "\n",
    "            # Get shape:\n",
    "            h, w = data_tmp.shape\n",
    "\n",
    "            # Overwrite:\n",
    "            projected_data[key] = self.data[key].iloc[:h, :w].copy()\n",
    "\n",
    "            projected_data[key].iloc[:, :] = data_tmp\n",
    "\n",
    "            projected_data[key].index = indices\n",
    "\n",
    "        # Return:\n",
    "        return projected_data\n",
    "\n",
    "    # Method for lagging data:\n",
    "    def lag_n_lead_data(self, data, variables, lag, lead):\n",
    "            \n",
    "        \"\"\"Lags and leads data for each variable and returns data as a single dataframe. Lag must be at least 1 and lead must be at least 0.\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        # Initialize:\n",
    "        shift_data = {}\n",
    "        data_tmp = None\n",
    "\n",
    "        # Create data list:\n",
    "        data_list = []\n",
    "        \n",
    "        if variables is None:\n",
    "            data_list.append(None)\n",
    "\n",
    "        else:\n",
    "                \n",
    "            # If lag is needed:\n",
    "            if lag > 0:\n",
    "                \n",
    "                # Iterate over lags (in reverse):\n",
    "                for i in range(1, lag+1)[::-1]:\n",
    "                    \n",
    "                    # Iterate over variables:\n",
    "                    for key in variables:\n",
    "\n",
    "                        # Create copy:\n",
    "                        data_copy = data[key].copy()\n",
    "                        \n",
    "                        # Create copy of copy:\n",
    "                        data_copy_copy = data_copy.copy()\n",
    "\n",
    "                        # Fix column names:\n",
    "                        data_copy_copy.columns = \\\n",
    "                            [f\"lag_{i}_{col}\" for col in data_copy_copy.columns]\n",
    "                        \n",
    "                        # Append shifted data:\n",
    "                        data_list.append(data_copy_copy.shift(i))\n",
    "                \n",
    "            else:\n",
    "                data_list.append(None)\n",
    "\n",
    "            # If lead is needed:\n",
    "            if lead > 0:\n",
    "        \n",
    "                # Iterate over leads:\n",
    "                for i in range(0, lead):\n",
    "\n",
    "                    # Iterate over variables:\n",
    "                    for key in variables:\n",
    "                        \n",
    "                        # Create copy:\n",
    "                        data_copy = data[key].copy()\n",
    "\n",
    "                        # Create copy of copy:\n",
    "                        data_copy_copy = data_copy.copy()\n",
    "\n",
    "                        # Fix column names:\n",
    "                        if i == 0:\n",
    "                            data_copy_copy.columns = \\\n",
    "                                [f\"{col}\" for col in data_copy_copy.columns]\n",
    "                        else:\n",
    "                            data_copy_copy.columns = \\\n",
    "                                [f\"lead_{i}_{col}\" for col in data_copy_copy.columns]\n",
    "                        \n",
    "                        # Append shifted data:\n",
    "                        data_list.append(data_copy_copy.shift(-i))\n",
    "\n",
    "            else:\n",
    "                data_list.append(None)\n",
    "\n",
    "\n",
    "        # Concatenate:\n",
    "        data_tmp = pd.concat(data_list, axis=1).dropna()\n",
    "\n",
    "        # Overwrite:\n",
    "        shift_data = data_tmp\n",
    "\n",
    "        # Return:\n",
    "        return shift_data\n",
    "\n",
    "    # Method for splitting data:\n",
    "    def split_data(self, data, train_frac):\n",
    "                \n",
    "            \"\"\"Splits data into train and test sets.\"\"\"\n",
    "            \n",
    "            # Split:\n",
    "            train_data, test_data = train_test_split(data, train_size=train_frac, shuffle=False)\n",
    "    \n",
    "            # Return:\n",
    "            return train_data, test_data\n",
    "     \n",
    "    \n",
    "# Create storage object:\n",
    "storage = Storage()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipeline classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PIPELINE PROCESSING BLOCKS:\n",
    "\n",
    "class Setup(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, scaler, projector, vars):\n",
    "        print(\"Setup.__init__\")\n",
    "        self.scaler = scaler\n",
    "        self.projector = projector\n",
    "        self.vars = vars\n",
    "        storage.load_scalers(scaler, vars)\n",
    "        storage.load_projectors(projector, vars)\n",
    "        storage.fit_scalers(vars)\n",
    "        storage.fit_projectors(vars)\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        print(\"Setup.fit\") \n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        print(\"Setup.transform\")\n",
    "        return X # Return X as a tuple\n",
    "\n",
    "\n",
    "class GetDicts(BaseEstimator, TransformerMixin):\n",
    "    \"\"\" Gets dictionaries of dataframes.\"\"\"\n",
    "    def __init__(self, input_vars, extra_vars):\n",
    "        if storage.debug:\n",
    "            print(\"GetDicts.__init__\")\n",
    "\n",
    "        self.input_vars = input_vars\n",
    "        self.extra_vars = extra_vars\n",
    "        self.output_vars = input_vars\n",
    "        self.y = None\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        if storage.debug:\n",
    "            print(\"GetDicts.fit\")\n",
    "\n",
    "        # Convert y to dictionary:\n",
    "        self.y = storage.df2dicts(y, self.output_vars)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "\n",
    "        if storage.debug:\n",
    "            print(\"GetDicts.transform\")\n",
    "\n",
    "        # Convert X to dictionary:\n",
    "        X1 = storage.df2dicts(X, self.input_vars)\n",
    "        E1 = storage.df2dicts(X, self.extra_vars)\n",
    "\n",
    "        # Output handling:\n",
    "        if self.y is not None:\n",
    "            y1 = self.y\n",
    "            self.y = None\n",
    "\n",
    "            return self.input_vars, self.extra_vars, self.output_vars, X1, E1, y1 \n",
    "        \n",
    "        else:\n",
    "            return self.input_vars, self.extra_vars, self.output_vars, X1, E1\n",
    "        \n",
    "\n",
    "class DataScaler(BaseEstimator, TransformerMixin):\n",
    "    \"\"\" Scales data.\"\"\"\n",
    "    def __init__(self, direction, scaler=None):\n",
    "        if storage.debug:\n",
    "            print(\"DataScaler.__init__\")\n",
    "        self.direction = direction\n",
    "        \n",
    "        if scaler == \"standard\":\n",
    "            self.scaler = StandardScaler()\n",
    "        else:\n",
    "            self.scaler = scaler\n",
    "            \n",
    "        self.y_org = None\n",
    "        self.y = None\n",
    "\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\" Always receives a tuple of (X, E, y) and returns self.\"\"\"\n",
    "        if storage.debug:\n",
    "            print(\"DataScaler.fit\")\n",
    "\n",
    "        if self.direction == \"forward\":\n",
    "            \n",
    "            # Extract variables:\n",
    "            input_vars, _, _, _, _, y1 = X\n",
    "\n",
    "            # Store data:\n",
    "            self.y_org = y1\n",
    "            self.y = y1\n",
    "\n",
    "            # Conditional: \n",
    "            if self.scaler is not None:\n",
    "\n",
    "                # Load and fit scalers:\n",
    "                storage.load_scalers(self.scaler, input_vars)\n",
    "                storage.fit_scalers(input_vars)\n",
    "\n",
    "                # Scale data:\n",
    "                self.y = storage.scale_data(self.direction, self.y, input_vars)\n",
    "           \n",
    "            return self\n",
    "\n",
    "        if self.direction == \"backward\":\n",
    "            return self\n",
    "\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\" Can receive a tuple of (X, E, y) or (X, E) and returns a tuple of (X, E, y) or (X, E). \"\"\"\n",
    "        if storage.debug:\n",
    "            print(\"DataScaler.transform\")\n",
    "\n",
    "        if self.direction == \"forward\":\n",
    "                \n",
    "            # Input handling:\n",
    "            if len(X) == 6:\n",
    "                input_vars, extra_vars, output_vars, X1, E1, _ = X \n",
    "            \n",
    "            elif len(X) == 5:\n",
    "                input_vars, extra_vars, output_vars, X1, E1 = X  \n",
    "\n",
    "            # Conditional:\n",
    "            if self.scaler is not None:\n",
    "\n",
    "                # Scale data:\n",
    "                X1 = storage.scale_data(self.direction, X1, input_vars)\n",
    "\n",
    "            # Output handling:\n",
    "            if self.y is not None:\n",
    "                y1 = self.y\n",
    "                self.y = None\n",
    "\n",
    "                return self.scaler, input_vars, extra_vars, output_vars, X1, E1, y1 \n",
    "\n",
    "            else:\n",
    "                return self.scaler, input_vars, extra_vars, output_vars, X1, E1 \n",
    "\n",
    "        if self.direction == \"backward\":\n",
    "            \n",
    "            # Extract data:\n",
    "            scaler, output_vars, y_pred = X\n",
    "\n",
    "            if scaler is not None:\n",
    "                    \n",
    "                # Rescale data:\n",
    "                y_pred = storage.scale_data(self.direction, y_pred, output_vars)\n",
    "            \n",
    "            return y_pred\n",
    "\n",
    "\n",
    "class DataProjector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\" Projects data.\"\"\"\n",
    "    def __init__(self, direction, projector=None, n_dim=1):\n",
    "        if storage.debug:\n",
    "            print(\"DataProjector.__init__\")\n",
    "        self.direction = direction\n",
    "        self.n_dim = n_dim\n",
    "        if projector == \"ipca\":\n",
    "            self.projector = IncrementalPCA(n_components=self.n_dim)\n",
    "        else:\n",
    "            self.projector = projector\n",
    "        \n",
    "        self.y_org = None\n",
    "        self.y = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        if storage.debug:\n",
    "            print(\"DataProjector.fit\")\n",
    "\n",
    "        if self.direction == \"forward\":\n",
    "\n",
    "            # Extract variables:\n",
    "            _, input_vars, _, _, _, _, y1 = X\n",
    "\n",
    "            # Store data:\n",
    "            self.y_org = y1\n",
    "            self.y = y1\n",
    "\n",
    "            # Conditional:\n",
    "            if self.projector is not None:\n",
    "\n",
    "                # Load and fit projectors:\n",
    "                storage.load_projectors(self.projector, input_vars)\n",
    "                storage.fit_projectors(input_vars)\n",
    "\n",
    "                # Project data:\n",
    "                self.y = storage.project_data(self.direction, self.y, input_vars)\n",
    "            \n",
    "            return self\n",
    "\n",
    "        if self.direction == \"backward\":\n",
    "            return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        if storage.debug:\n",
    "            print(\"DataProjector.transform\")\n",
    "\n",
    "        if self.direction == \"forward\":\n",
    "\n",
    "            # Input handling:\n",
    "            if len(X) == 7:\n",
    "                scaler, input_vars, extra_vars, output_vars, X1, E1, _ = X \n",
    "            \n",
    "            elif len(X) == 6:\n",
    "                scaler, input_vars, extra_vars, output_vars, X1, E1 = X \n",
    "                  \n",
    "            if self.projector is not None:\n",
    "\n",
    "                # Project data: \n",
    "                X1 = storage.project_data(self.direction, X1, input_vars)\n",
    "\n",
    "            # Output handing:\n",
    "            if self.y is not None:\n",
    "                y1 = self.y\n",
    "                self.y = None\n",
    "\n",
    "                return scaler, self.projector, input_vars, extra_vars, output_vars, X1, E1, y1 \n",
    "            \n",
    "            else:\n",
    "                return scaler, self.projector, input_vars, extra_vars, output_vars, X1, E1\n",
    "        \n",
    "        if self.direction == \"backward\":\n",
    "\n",
    "            # Extract data:\n",
    "            scaler, projector, _, _, output_vars, y_pred = X\n",
    "            \n",
    "            if projector is not None:\n",
    "                    \n",
    "                # Reproject data:\n",
    "                y_pred = storage.project_data(self.direction, y_pred, output_vars)\n",
    "\n",
    "            return scaler, output_vars, y_pred\n",
    "\n",
    "\n",
    "class DataLagger(BaseEstimator, TransformerMixin):\n",
    "    \"\"\" Lags and leads data.\"\"\"\n",
    "    def __init__(self, lag, lead):\n",
    "        if storage.debug:\n",
    "            print(\"DataLagger.__init__\")\n",
    "        self.lag = lag\n",
    "        self.lead = lead\n",
    "        self.y = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        if storage.debug:\n",
    "            print(\"DataLagger.fit\")\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        if storage.debug:\n",
    "            print(\"DataLagger.transform\")\n",
    "        \n",
    "        # Input handling:\n",
    "        if len(X) == 8:\n",
    "            scaler, projector, input_vars, extra_vars, output_vars, X1, E1, self.y = X\n",
    "\n",
    "        elif len(X) == 7:\n",
    "            scaler, projector, input_vars, extra_vars, output_vars, X1, E1 = X\n",
    "\n",
    "        # Conditional:\n",
    "        if self.y is not None:\n",
    "            self.y = storage.lag_n_lead_data(self.y, output_vars, lag=0, lead=1)\n",
    "\n",
    "        # Lag and lead:\n",
    "        X1 = storage.lag_n_lead_data(X1, input_vars, self.lag, self.lead)        \n",
    "\n",
    "        # Output handling:\n",
    "        if self.y is not None:\n",
    "            y1 = self.y\n",
    "            self.y = None\n",
    "            return scaler, projector, input_vars, extra_vars, output_vars, X1, E1, y1\n",
    "        \n",
    "        else:\n",
    "            return scaler, projector, input_vars, extra_vars, output_vars, X1, E1  \n",
    "\n",
    "\n",
    "class ExtraLagger(BaseEstimator, TransformerMixin):\n",
    "    \"\"\" Lags and leads extra variables.\"\"\"\n",
    "    def __init__(self, lag, lead):\n",
    "        if storage.debug:\n",
    "            print(\"ExtraLagger.__init__\")\n",
    "        self.lag = lag\n",
    "        self.lead = lead\n",
    "        self.y = None\n",
    "\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        if storage.debug:\n",
    "            print(\"ExtraLagger.fit\")\n",
    "        return self\n",
    "\n",
    "\n",
    "    def transform(self, X):\n",
    "        if storage.debug:\n",
    "            print(\"ExtraLagger.transform\")\n",
    "\n",
    "        # Input handling:\n",
    "        if len(X) == 8:\n",
    "            scaler, projector, input_vars, extra_vars, output_vars, X1, E1, self.y = X\n",
    "        \n",
    "        elif len(X) == 7:\n",
    "            scaler, projector, input_vars, extra_vars, output_vars, X1, E1 = X\n",
    "\n",
    "\n",
    "        # Lag and lead:\n",
    "        E1 = storage.lag_n_lead_data(E1, extra_vars, self.lag, self.lead)\n",
    "\n",
    "        \n",
    "        # Output handling:\n",
    "        if self.y is not None:\n",
    "            y1 = self.y\n",
    "            self.y = None\n",
    "\n",
    "            return scaler, projector, input_vars, extra_vars, output_vars, X1, E1, y1  \n",
    "        \n",
    "        else:\n",
    "            return scaler, projector, input_vars, extra_vars, output_vars, X1, E1 \n",
    "\n",
    "\n",
    "class FixIndices(BaseEstimator, TransformerMixin):\n",
    "    \"\"\" Finds common indices of X, y, and E, and strips away the rest.\"\"\"\n",
    "    def __init__(self):\n",
    "        if storage.debug:\n",
    "            print(\"FixIndices.__init__\")\n",
    "        self.y = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        if storage.debug:\n",
    "            print(\"FixIndices.fit\")\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        if storage.debug:\n",
    "            print(\"FixIndices.transform\")\n",
    "\n",
    "        # Input handling:\n",
    "        if len(X) == 8:\n",
    "            scaler, projector, input_vars, extra_vars, output_vars, X1, E1, self.y = X  \n",
    "\n",
    "        elif len(X) == 7:\n",
    "            scaler, projector, input_vars, extra_vars, output_vars, X1, E1 = X  \n",
    "\n",
    "\n",
    "        # Find common indices:\n",
    "        indices = X1.index.intersection(E1.index)\n",
    "\n",
    "        # Conditional:\n",
    "        if self.y is not None:\n",
    "            indices = indices.intersection(self.y.index)\n",
    "    \n",
    "        # Overwrite:\n",
    "        X1 = X1.loc[indices, :]\n",
    "        E1 = E1.loc[indices, :]\n",
    "\n",
    "\n",
    "        # Output handling:\n",
    "        if self.y is not None:\n",
    "            y1 = self.y\n",
    "            self.y = None\n",
    "\n",
    "            # Overwrite:\n",
    "            y1 = y1.loc[indices, :]\n",
    "\n",
    "            indices = None\n",
    "\n",
    "            return scaler, projector, input_vars, extra_vars, output_vars, X1, E1, y1 \n",
    "        \n",
    "        else:\n",
    "            return scaler, projector, input_vars, extra_vars, output_vars, X1, E1  \n",
    "\n",
    "\n",
    "# PIPELINE MODEL BLOCKS:\n",
    "class LinearRegressor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        if storage.debug:\n",
    "            print(\"LinearRegressor.__init__\")\n",
    "        self.model = LinearRegression()\n",
    "        self.y = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        if storage.debug:\n",
    "            print(\"LinearRegressor.fit\")\n",
    "\n",
    "        # Extract data:\n",
    "        _, _, _, _, _, X1, E1, y1 = X\n",
    "\n",
    "        # Combine X and E:\n",
    "        train_input = pd.concat([X1, E1], axis=1)\n",
    "        train_target = y1\n",
    "\n",
    "        # Fit:\n",
    "        self.model.fit(X=train_input, y=train_target)\n",
    "        \n",
    "        self.y = y1\n",
    "\n",
    "        return self\n",
    "\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        if storage.debug:\n",
    "            print(\"LinearRegressor.transform\")\n",
    "\n",
    "        # Input handling:\n",
    "        if len(X) == 8:\n",
    "            scaler, projector, input_vars, extra_vars, output_vars, X1, E1, _ = X\n",
    "\n",
    "        elif len(X) == 7:\n",
    "            scaler, projector, input_vars, extra_vars, output_vars, X1, E1 = X\n",
    "\n",
    "        # Combine X and E:\n",
    "        test_input = pd.concat([X1, E1], axis=1)\n",
    "\n",
    "        y_pred = pd.DataFrame(index=test_input.index, columns=self.y.columns)\n",
    "\n",
    "        # Predict:\n",
    "        y_pred.values[:] = self.model.predict(test_input)\n",
    "    \n",
    "        return scaler, projector, input_vars, extra_vars, output_vars, y_pred\n",
    "\n",
    "\n",
    "class XGBoostRegressor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, n_estimators, max_depth, learning_rate,\n",
    "                 random_state=42, verbosity=10):\n",
    "\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        self.learning_rate = learning_rate\n",
    "        self.random_state = random_state\n",
    "        self.verbosity = verbosity\n",
    "        \n",
    "\n",
    "        if storage.debug:\n",
    "            print(\"XGBRegressor.__init__\")\n",
    "\n",
    "        self.model = XGBR(n_estimators=self.n_estimators,\n",
    "                          max_depth=self.max_depth, \n",
    "                          learning_rate=self.learning_rate, \n",
    "                          random_state=self.random_state, \n",
    "                          verbosity=self.verbosity)\n",
    "        self.y = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "\n",
    "        if storage.debug:\n",
    "            print(\"XGBRegressor.fit\")\n",
    "\n",
    "        # Extract data:\n",
    "        _, _, _, _, _, X1, E1, y1 = X\n",
    "\n",
    "        # Combine X and E:\n",
    "        train_input = pd.concat([X1, E1], axis=1)\n",
    "        train_target = y1\n",
    "\n",
    "        # Fit:\n",
    "        self.model.fit(X=train_input, y=train_target)\n",
    "        \n",
    "        self.y = y1\n",
    "\n",
    "        return self\n",
    "\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        if storage.debug:\n",
    "            print(\"XGBRegressor.transform\")\n",
    "\n",
    "        # Input handling:\n",
    "        if len(X) == 8:\n",
    "            scaler, projector, input_vars, extra_vars, output_vars, X1, E1, _ = X\n",
    "\n",
    "        elif len(X) == 7:\n",
    "            scaler, projector, input_vars, extra_vars, output_vars, X1, E1 = X\n",
    "\n",
    "        # Combine X and E:\n",
    "        test_input = pd.concat([X1, E1], axis=1)\n",
    "\n",
    "        y_pred = pd.DataFrame(index=test_input.index, columns=self.y.columns)\n",
    "\n",
    "        # Predict:\n",
    "        y_pred.values[:] = self.model.predict(test_input)\n",
    "    \n",
    "        return scaler, projector, input_vars, extra_vars, output_vars, y_pred\n",
    "\n",
    "class DMDc():\n",
    "\n",
    "    def __init__(self, input_modes, extra_modes):\n",
    "        self.input_modes = input_modes\n",
    "        self.extra_modes = extra_modes\n",
    "\n",
    "    def fit(self, X, E, y):\n",
    "        \"\"\" Fits the DMDc model to the data.\"\"\"\n",
    "\n",
    "        # Renaming:\n",
    "        X_prime = y.values\n",
    "        X_c = E.values\n",
    "        X = X.values\n",
    "        p = self.input_modes + self.extra_modes\n",
    "        r = self.input_modes\n",
    "        n = X.shape[1]\n",
    "\n",
    "        # Step 0: Flip matrices (Columns=Snapshots)\n",
    "        X_prime = X_prime.T\n",
    "        X = X.T\n",
    "        X_c = X_c.T\n",
    "            \n",
    "        # Step 1: Construct Omega:\n",
    "        Omega = np.concatenate([X, X_c], axis=0)\n",
    "        \n",
    "        # Step 2: Compute the (tilde)-SVD of Omega\n",
    "        U_tilde, S_tilde, VT_tilde = np.linalg.svd(Omega, full_matrices=0)\n",
    "        \n",
    "        S_tilde_org = S_tilde\n",
    "        \n",
    "        # Step 2.1: Truncate with value p (> r):\n",
    "        U_tilde = U_tilde[:, :p]\n",
    "        S_tilde = np.diag(S_tilde[:p])\n",
    "        VT_tilde = VT_tilde[:p, :]\n",
    "        \n",
    "        # Step 2.2: Split U_tilde into 2:\n",
    "        U_tilde1 = U_tilde[:n, :]\n",
    "        U_tilde2 = U_tilde[n:, :]\n",
    "        \n",
    "        # Step 3: Compute the (hat)-SVD of X_prime:\n",
    "        U_hat, S_hat, VT_hat = np.linalg.svd(X_prime, full_matrices=0)\n",
    "        \n",
    "        S_hat_org = S_hat\n",
    "        \n",
    "        # Step 3.1: Truncate with value r (< p):\n",
    "        U_hat = U_hat[:, :r]\n",
    "        S_hat = np.diag(S_hat[:r])\n",
    "        VT_hat = VT_hat[:r, :]\n",
    "        \n",
    "        # Step 4: Compute A and B:\n",
    "        XVS = np.linalg.solve(S_tilde.T, (X_prime @ VT_tilde.T).T).T\n",
    "\n",
    "        A_tilde = U_hat.T @ XVS @ U_tilde1.T @ U_hat\n",
    "        B_tilde = U_hat.T @ XVS @ U_tilde2.T\n",
    "        \n",
    "        # Step 5: Eigenvalue decomposition:\n",
    "        Lambda, W = np.linalg.eig(A_tilde)\n",
    "        \n",
    "        # Extras: Correct the ordering of eigenvalues and eigenvectors:\n",
    "        idx = Lambda.argsort()[::-1]\n",
    "        Lambda = np.diag(Lambda[idx])\n",
    "        W = W[:, idx]\n",
    "        \n",
    "        # Step 6: Compute the dynamic modes of A:\n",
    "        Phi = XVS @ U_tilde1.T @ U_hat @ W \n",
    "\n",
    "        # Keep data:\n",
    "        self.A_tilde = A_tilde\n",
    "        self.B_tilde = B_tilde\n",
    "        self.Phi = Phi\n",
    "        self.U_hat = U_hat\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X, E):\n",
    "        \"\"\" Predicts the next value from data.\"\"\"\n",
    "\n",
    "        X = X.T\n",
    "        E = E.T\n",
    "\n",
    "        X_tilde = self.U_hat.T @ X\n",
    "        \n",
    "        y_tilde = self.A_tilde @ X_tilde + self.B_tilde @ E\n",
    "\n",
    "        y = self.U_hat @ y_tilde\n",
    "\n",
    "        return y.T\n",
    "    \n",
    "    def predict_linked(self, X, E):\n",
    "        \"\"\" Predicts the next value from data and previous predictions.\"\"\"\n",
    "\n",
    "        X = X.T\n",
    "        E = E.T\n",
    "\n",
    "        X_tilde = self.U_hat.T @ X[:, 0]\n",
    "\n",
    "        x_tilde_list = []\n",
    "\n",
    "        for k in tqdm(range(X.shape[1])):\n",
    "            X_tilde = self.A_tilde @ X_tilde + self.B_tilde @ E[:, k]\n",
    "            x_tilde_list.append(X_tilde)\n",
    "\n",
    "\n",
    "        y = self.U_hat @ np.array(x_tilde_list).T\n",
    "\n",
    "        return y.T\n",
    "\n",
    "class DMDcRegressor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, input_modes=None, extra_modes=None):\n",
    "\n",
    "        if storage.debug:\n",
    "            print(\"DMDcRegressor.__init__\")\n",
    "\n",
    "        self.input_modes = input_modes\n",
    "        self.extra_modes = extra_modes\n",
    "\n",
    "        self.model = DMDc(self.input_modes, self.extra_modes)\n",
    "\n",
    "        self.y = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "\n",
    "        if storage.debug:\n",
    "            print(\"DMDcRegressor.fit\")\n",
    "\n",
    "        # Extract data:\n",
    "        _, _, _, _, _, X1, E1, y1 = X\n",
    "\n",
    "        # Fit:\n",
    "        self.model.fit(X1, E1, y1)\n",
    "        \n",
    "        self.y = y1\n",
    "\n",
    "        return self\n",
    "\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        if storage.debug:\n",
    "            print(\"DMDRegressor.transform\")\n",
    "\n",
    "        # Input handling:\n",
    "        if len(X) == 8:\n",
    "            scaler, projector, input_vars, extra_vars, output_vars, X1, E1, _ = X\n",
    "\n",
    "        elif len(X) == 7:\n",
    "            scaler, projector, input_vars, extra_vars, output_vars, X1, E1 = X\n",
    "\n",
    "        y_pred = pd.DataFrame(index=X1.index, columns=self.y.columns)\n",
    "\n",
    "        # Predict:\n",
    "        y_pred.values[:] = self.model.predict(X1, E1)\n",
    "    \n",
    "        return scaler, projector, input_vars, extra_vars, output_vars, y_pred\n",
    "      \n",
    "\n",
    "# PIPELINE POSTPROCESSING BLOCKS:\n",
    "class RecoverDict(BaseEstimator, TransformerMixin):\n",
    "    \"\"\" Recovers dictionary of dataframes from data.\"\"\"\n",
    "    def __init__(self):\n",
    "        if storage.debug:\n",
    "            print(\"RecoverDict.__init__\")\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        if storage.debug:\n",
    "            print(\"RecoverDict.fit\")\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        if storage.debug:\n",
    "            print(\"RecoverDict.transform\")\n",
    "\n",
    "        # Extract data:\n",
    "        scaler, projector, input_vars, extra_vars, output_vars, y_pred = X\n",
    "\n",
    "        y_pred = storage.df2dicts(y_pred, output_vars)\n",
    "\n",
    "        return scaler, projector, input_vars, extra_vars, output_vars, y_pred\n",
    "\n",
    "\n",
    "class DummyEstimator(BaseEstimator, TransformerMixin):\n",
    "    \"\"\" A simple class to ensure that all fit and transform methods of classes before the Dummy are called, due to the way sklearn pipelines work. \"\"\"\n",
    "    \n",
    "    def __init__(self, test=False):\n",
    "        if storage.debug:\n",
    "            print(\"DummyEstimator.__init__\")\n",
    "        self.test = test\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        if storage.debug:\n",
    "            print(\"DummyEstimator.fit\")\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        if storage.debug:\n",
    "            print(\"DummyEstimator.predict\")\n",
    "\n",
    "        if self.test:\n",
    "\n",
    "            # Extract data:\n",
    "            scaler, projector, input_vars, extra_vars, output_vars, y_pred = X\n",
    "\n",
    "            # Check projector:\n",
    "            if projector is not None:\n",
    "\n",
    "                y_pred = storage.project_data(\"backward\", y_pred, output_vars)\n",
    "\n",
    "            # Check scaler:\n",
    "            if scaler is not None:\n",
    "\n",
    "                y_pred = storage.scale_data(\"backward\", y_pred, output_vars)\n",
    "\n",
    "            return y_pred\n",
    "        \n",
    "        else:\n",
    "            return X\n",
    "\n",
    "   \n",
    "### TSCV MIGHT BE USEFUL HERE ###\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.TimeSeriesSplit.html    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data into storage:\n",
    "storage.load_data(df)\n",
    "\n",
    "# Define input and extra variables:\n",
    "input_vars = [\"z\", \"u\", \"v\"]\n",
    "extra_vars = [\"bcs\", \"bcn\", \"wu\", \"wv\"]\n",
    "\n",
    "# Load inputs, extra and outputs:\n",
    "input_data_dict = storage.get_data(input_vars)\n",
    "extra_data_dict = storage.get_data(extra_vars)\n",
    "output_data_dict = storage.get_data(input_vars)\n",
    "\n",
    "# Concatenate inputs, extras and outputs:\n",
    "input_data_df = storage.dicts2df(input_data_dict, input_vars)\n",
    "extra_data_df = storage.dicts2df(extra_data_dict, extra_vars)\n",
    "output_data_df = storage.dicts2df(output_data_dict, input_vars)\n",
    "\n",
    "# Define input and target variables for pipeline:\n",
    "X_df = pd.concat([input_data_df, extra_data_df], axis=1)\n",
    "y_df = output_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   26.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores (LinearRegressor): [0.13452574 0.10604277]\n",
      "Mean score (LinearRegressor): 0.12028425808049349\n",
      "Std score (LinearRegressor): 0.014241484613632685\n"
     ]
    }
   ],
   "source": [
    "# Define pipeline:\n",
    "pipeline_lr = Pipeline([\n",
    "    (\"get_dicts\", GetDicts(input_vars=input_vars, \n",
    "                           extra_vars=extra_vars)),\n",
    "    (\"scaler\", DataScaler(direction=\"forward\", scaler=\"standard\")),\n",
    "    (\"projector\", DataProjector(direction=\"forward\", projector=\"ipca\")),\n",
    "    (\"lag_n_lead_data\", DataLagger(lag=1, lead=0)),\n",
    "    (\"lag_n_lead_extra\", ExtraLagger(lag=1, lead=1)),\n",
    "    (\"merge_indices\", FixIndices()),\n",
    "    (\"model\", LinearRegressor()),\n",
    "    (\"dict_recover\", RecoverDict()),\n",
    "    (\"reprojector\", DataProjector(direction=\"backward\", projector=None)),\n",
    "    (\"rescaler\", DataScaler(direction=\"backward\", scaler=None)),\n",
    "    (\"estimator\", DummyEstimator())\n",
    "], verbose=False)\n",
    "\n",
    "# Define pipeline:\n",
    "pipeline_xgb = Pipeline([\n",
    "    (\"get_dicts\", GetDicts(input_vars=input_vars, \n",
    "                           extra_vars=extra_vars)),\n",
    "    (\"scaler\", DataScaler(direction=\"forward\", scaler=StandardScaler())),\n",
    "    (\"projector\", DataProjector(direction=\"forward\", projector=IncrementalPCA())),\n",
    "    (\"lag_n_lead_data\", DataLagger(lag=1, lead=0)),\n",
    "    (\"lag_n_lead_extra\", ExtraLagger(lag=1, lead=1)),\n",
    "    (\"merge_indices\", FixIndices()),\n",
    "    (\"model\", XGBoostRegressor(n_estimators=1, max_depth=1, learning_rate=1)),\n",
    "    (\"dict_recover\", RecoverDict()),\n",
    "    (\"reprojector\", DataProjector(direction=\"backward\", projector=None)),\n",
    "    (\"rescaler\", DataScaler(direction=\"backward\", scaler=None)),\n",
    "    (\"estimator\", DummyEstimator())\n",
    "], verbose=False)\n",
    "\n",
    "# Define pipeline:\n",
    "pipeline_dmdc = Pipeline([\n",
    "    (\"get_dicts\", GetDicts(input_vars=input_vars, \n",
    "                           extra_vars=extra_vars)),\n",
    "    (\"scaler\", DataScaler(direction=\"forward\", scaler=None)),\n",
    "    (\"projector\", DataProjector(direction=\"forward\", projector=None)),\n",
    "    (\"lag_n_lead_data\", DataLagger(lag=1, lead=0)),\n",
    "    (\"lag_n_lead_extra\", ExtraLagger(lag=1, lead=1)),\n",
    "    (\"merge_indices\", FixIndices()),\n",
    "    (\"model\", DMDcRegressor(input_modes=2, extra_modes=2)),\n",
    "    (\"dict_recover\", RecoverDict()),\n",
    "    (\"reprojector\", DataProjector(direction=\"backward\", projector=None)),\n",
    "    (\"rescaler\", DataScaler(direction=\"backward\", scaler=None)),\n",
    "    (\"estimator\", DummyEstimator())\n",
    "], verbose=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define parameter grid:\n",
    "param_grid_lr = {\n",
    "    \"get_dicts__input_vars\": [[\"z\"]],\n",
    "    \"get_dicts__extra_vars\": [[None], [\"bcn\", \"bcs\"], [\"wu\", \"wv\"], [\"bcn\", \"bcs\", \"wu\", \"wv\"]],\n",
    "    \"projector__n_dim\": [10**(i) for i in range(0, 4)],\n",
    "    \"lag_n_lead_data__lag\": [i for i in range(1, 6)],\n",
    "    \"lag_n_lead_data__lead\": [0],\n",
    "    \"lag_n_lead_extra__lag\": [i for i in range(1, 6)],\n",
    "    \"lag_n_lead_extra__lead\": [i for i in range(1, 6)],\n",
    "}\n",
    "\n",
    "# Define parameter grid:\n",
    "param_grid_xgb = {\n",
    "    \"get_dicts__input_vars\": [[\"z\"]],\n",
    "    \"get_dicts__extra_vars\": [[None], [\"bcn\", \"bcs\"], [\"wu\", \"wv\"], [\"bcn\", \"bcs\", \"wu\", \"wv\"]],\n",
    "    \"projector__n_dim\": [int(10**(i)) for i in range(0, 4)],    \n",
    "    \"lag_n_lead_data__lag\": [i for i in range(1, 6)],\n",
    "    \"lag_n_lead_data__lead\": [0],\n",
    "    \"lag_n_lead_extra__lag\": [i for i in range(1, 6)],\n",
    "    \"lag_n_lead_extra__lead\": [i for i in range(1, 6)],\n",
    "    \"model__n_estimators\": [int(i*10) for i in range(1, 6)],\n",
    "    \"model__max_depth\": [i for i in range(1, 6)],\n",
    "    \"model__learning_rate\": [0.1, 0.01, 0.001],\n",
    "}\n",
    "\n",
    "# Define parameter grid:\n",
    "param_grid_dmdc = {\n",
    "    \"get_dicts__input_vars\": [[\"z\"]],\n",
    "    \"get_dicts__extra_vars\": [[None], [\"bcn\", \"bcs\"], [\"wu\", \"wv\"], [\"bcn\", \"bcs\", \"wu\", \"wv\"]],\n",
    "    \"lag_n_lead_data__lag\": [i for i in range(1, 6)],\n",
    "    \"lag_n_lead_data__lead\": [0],\n",
    "    \"lag_n_lead_extra__lag\": [i for i in range(1, 6)],\n",
    "    \"lag_n_lead_extra__lead\": [i for i in range(1, 6)],\n",
    "    \"model__input_modes\": [1, 10, 100, 500],\n",
    "    \"model__extra_modes\": [1, 10, 100],\n",
    "}\n",
    "\n",
    "\n",
    "# Get mikeio area data:\n",
    "img_data = mf.get_mikeio_format()\n",
    "\n",
    "mesh_weights = img_data.geometry.get_element_area()\n",
    "\n",
    "# Define custom scoring setup:\n",
    "custom_scorer = make_scorer(mf.compute_metric, \n",
    "                            greater_is_better=False,\n",
    "                            kwargs={\"metric\": \"rmse\", \n",
    "                                    \"axis\": \"time\",\n",
    "                                    \"weights\": mesh_weights,\n",
    "                                    \"neg\": True})\n",
    "\n",
    "# Define cross-validation setup:\n",
    "cv = TimeSeriesSplit(n_splits=2)\n",
    "\n",
    "# Set debug mode:\n",
    "storage.debug = False\n",
    "\n",
    "# Test cross-validation:\n",
    "if 1:\n",
    "    scores_lr = cross_validate(pipeline_lr, X_df, y_df, \n",
    "                               cv=cv, scoring=custom_scorer, \n",
    "                               return_estimator=False, \n",
    "                               verbose=1, n_jobs=1, error_score=\"raise\")\n",
    "\n",
    "    # Print scores:\n",
    "    print(f\"Scores (LinearRegressor): {scores_lr['test_score']}\")\n",
    "    print(f\"Mean score (LinearRegressor): {np.mean(scores_lr['test_score'])}\")\n",
    "    print(f\"Std score (LinearRegressor): {np.std(scores_lr['test_score'])}\")\n",
    "    \n",
    "    \n",
    "\n",
    "    scores_dmdc = cross_validate(pipeline_dmdc, X_df, y_df, cv=cv, scoring=custom_scorer,\n",
    "                            return_estimator=False,\n",
    "                            verbose=1, n_jobs=1, error_score=\"raise\")\n",
    "\n",
    "    # Print scores:\n",
    "    print(f\"Scores: (DMDcRegressor) {scores_dmdc['test_score']}\")\n",
    "    print(f\"Mean score:(DMDcRegressor) {np.mean(scores_dmdc['test_score'])}\")\n",
    "    print(f\"Std score: (DMDcRegressor) {np.std(scores_dmdc['test_score'])}\")\n",
    "\n",
    "\n",
    "\n",
    "    scores_xgb = cross_validate(pipeline_xgb, X_df, y_df,\n",
    "                                cv=cv, scoring=custom_scorer,\n",
    "                                return_estimator=False,\n",
    "                                verbose=1, n_jobs=1, error_score=\"raise\")\n",
    "\n",
    "    # Print scores:\n",
    "    print(f\"Scores: (XGBRegressor) {scores_xgb['test_score']}\")\n",
    "    print(f\"Mean score (XGBRegressor): {np.mean(scores_xgb['test_score'])}\")\n",
    "    print(f\"Std score (XGBRegressor): {np.std(scores_xgb['test_score'])}\")\n",
    "\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "    \n",
    "if 0:     \n",
    "\n",
    "    max_iters = 1\n",
    "\n",
    "    # Test randomized search:\n",
    "    search_lr = RandomizedSearchCV(pipeline_lr, param_grid_lr, n_iter=max_iters,\n",
    "                                scoring=custom_scorer, n_jobs=1,\n",
    "                                cv=cv, verbose=10, refit=False,\n",
    "                                random_state=42, error_score=\"raise\")\n",
    "\n",
    "    \n",
    "    search_lr.fit(X_df, y_df)\n",
    "\n",
    "    # Print results:\n",
    "    print(f\"Best score (LinearRegressor): {search_lr.best_score_}\")\n",
    "    print(f\"Best params (LinearRegressor): {search_lr.best_params_}\")\n",
    "\n",
    "\n",
    "    # Test randomized search:\n",
    "    search_xgb = RandomizedSearchCV(pipeline_xgb, param_grid_xgb, n_iter=max_iters, \n",
    "                                    scoring=custom_scorer, n_jobs=1, cv=cv, \n",
    "                                    verbose=2, refit=False, random_state=42)\n",
    "\n",
    "    search_xgb.fit(X_df, y_df)\n",
    "\n",
    "    # Print results:\n",
    "    print(f\"Best score (XGBRegressor): {search_xgb.best_score_}\")\n",
    "    print(f\"Best params (XGBRegressor): {search_xgb.best_params_}\")\n",
    "\n",
    "    \n",
    "    # Test randomized search:\n",
    "    search_dmdc = RandomizedSearchCV(pipeline_dmdc, param_grid_dmdc, n_iter=max_iters, scoring=custom_scorer, n_jobs=1, cv=cv, verbose=2, refit=False, random_state=42)\n",
    "\n",
    "    search_dmdc.fit(X_df, y_df)\n",
    "\n",
    "    # Print results:\n",
    "    print(f\"Best score (DMDcRegressor): {search_dmdc.best_score_}\")\n",
    "    print(f\"Best params (DMDcRegressor): {search_dmdc.best_params_}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
